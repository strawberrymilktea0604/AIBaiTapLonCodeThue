{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "838fc189-1f4f-4dae-b47e-96ccb56702cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose training mode:\n",
      "1. Memory Optimized (Recommended)\n",
      "2. CPU Training\n",
      "3. Ultra Minimal\n",
      "4. Download Pretrained Models Only\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter choice (1/2/3/4) [default: 1]:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¥ Memory-Optimized YOLOv8 Red License Plate Training\n",
      "============================================================\n",
      "üñ•Ô∏è  GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "üíæ Total GPU Memory: 4.0 GB\n",
      "ü§ñ Using YOLOv8n (Nano) for memory efficiency...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.25M/6.25M [00:00<00:00, 11.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Memory-Optimized Configuration:\n",
      "   Image size: 416\n",
      "   Batch size: 2\n",
      "   Workers: 2\n",
      "   AMP enabled: True\n",
      "   Models will be saved to: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\\models\n",
      "============================================================\n",
      "üöÄ Starting memory-optimized training...\n",
      "Ultralytics 8.3.156  Python-3.12.4 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=2, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/minhk/Downloads/code thu/AI/NguyenLam/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=0.9, freeze=None, half=False, hsv_h=0.01, hsv_s=0.5, hsv_v=0.3, imgsz=416, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.005, lrf=0.1, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=red_plate_memory_opt, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/minhk/Downloads/code thu/AI/NguyenLam/dataset\\models, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\models\\red_plate_memory_opt, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.3, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.05, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 8.75MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 1.50.6 MB/s, size: 18.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\minhk\\Downloads\\code thu√™\\AI\\NguyenLam\\dataset\\train\\labels... 6351 images, 5 backgrounds, 0 c\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\train\\labels.cache\n",
      "WARNING 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 2.61.0 MB/s, size: 21.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\minhk\\Downloads\\code thu√™\\AI\\NguyenLam\\dataset\\valid\\labels... 2048 images, 3 backgrounds, 0 cor\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\valid\\labels.cache\n",
      "Plotting labels to C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\models\\red_plate_memory_opt\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.005' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\models\\red_plate_memory_opt\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100     0.209G      1.446      1.312      1.228          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:42<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.574       0.53      0.543      0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100     0.209G      1.517      1.128      1.329          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.611      0.612        0.6      0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100     0.209G      1.503       1.09      1.335          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.872      0.705        0.8      0.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100     0.209G      1.503      1.034      1.381          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.892      0.677      0.797      0.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100     0.209G      1.481     0.9787      1.357          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.804       0.68      0.791      0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100     0.209G      1.449     0.9392      1.338          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.86      0.756      0.841      0.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100     0.209G      1.442     0.9245      1.345          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.847      0.762      0.838      0.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100     0.209G      1.411     0.8508      1.315          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.895       0.79      0.874      0.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100     0.209G      1.398     0.8317      1.314          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195        0.9       0.81      0.888      0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100     0.209G      1.408     0.8198      1.315          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.904      0.828      0.889       0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100     0.209G      1.377     0.8066      1.301          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:42<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.91      0.823      0.895      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100     0.209G       1.38     0.7746      1.302          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:43<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.915      0.845      0.902      0.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100     0.209G      1.355     0.7704      1.285          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:42<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.922      0.836      0.904      0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100     0.209G      1.362     0.7542      1.279          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:42<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.902      0.841      0.902      0.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100     0.209G      1.359     0.7497      1.287          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.931      0.858      0.914       0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100     0.209G      1.349     0.7304      1.273          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:44<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.943      0.873      0.921      0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100     0.209G       1.34     0.7054      1.268          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.94      0.869      0.921      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100     0.209G      1.336     0.7175      1.261          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.946      0.867      0.918      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100     0.209G      1.334     0.7307      1.258          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.938      0.872      0.921      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100     0.209G       1.32     0.6963      1.248          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.964      0.886      0.931      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100     0.209G      1.324     0.7017      1.256          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:44<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.963      0.872      0.927       0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100     0.209G      1.313     0.6964      1.246          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.953      0.889       0.93      0.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100     0.209G      1.306     0.6929      1.246          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.959      0.885      0.933      0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100     0.209G      1.314     0.6801      1.245          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.957      0.887      0.936      0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100     0.209G      1.311     0.6633      1.241          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.963       0.88      0.933      0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100     0.209G      1.302      0.671      1.238          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:34<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.96      0.888      0.939      0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100     0.209G      1.294     0.6445      1.232          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.965      0.889      0.938      0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100     0.209G      1.279     0.6451      1.223          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.964      0.886      0.934      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100     0.209G      1.286     0.6319      1.228          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:33<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.976      0.895      0.943      0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100     0.209G      1.272     0.6189      1.221          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.967      0.902      0.942      0.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100     0.209G      1.277     0.6199      1.219          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979        0.9      0.946      0.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100     0.209G       1.26     0.6157      1.216          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:33<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.965      0.905      0.943      0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100     0.209G      1.263      0.618      1.211          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:32<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.963      0.908      0.947      0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100     0.209G       1.25     0.6112      1.205          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:34<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.978      0.899      0.948      0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100     0.209G      1.261     0.6057      1.211          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.973      0.898      0.946      0.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100     0.209G      1.244     0.5925      1.203          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.971      0.897      0.944      0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100     0.209G      1.245     0.5922      1.204          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.977      0.901      0.947      0.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100     0.209G      1.244     0.5877      1.197          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.968      0.901      0.943       0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100     0.209G      1.236     0.5874      1.201          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.974      0.904      0.946      0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100     0.209G      1.221      0.577      1.188          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:45<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979      0.903      0.949      0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100     0.209G       1.22     0.5714      1.186          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.98      0.904      0.946        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100     0.209G      1.226     0.5732      1.192          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.97       0.91      0.952      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100     0.209G      1.229     0.5722      1.194          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.977      0.899      0.949        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100     0.209G      1.215     0.5693      1.188          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.967      0.907       0.95      0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100     0.209G      1.218     0.5684      1.191          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.98      0.904       0.95      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100     0.209G       1.21     0.5672      1.186          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:41<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.974      0.901      0.949      0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100     0.209G      1.217     0.5666      1.187          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:41<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.98      0.902      0.951      0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100     0.209G      1.202     0.5528       1.18          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.975      0.899      0.948      0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100     0.209G      1.202     0.5527      1.179          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.973      0.907      0.948      0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100     0.209G      1.194     0.5517       1.17          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:34<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.972      0.905      0.951      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100     0.209G      1.201     0.5452      1.177          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.978      0.908      0.952      0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100     0.209G      1.188     0.5383      1.167          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:32<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.969      0.899      0.946      0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100     0.209G      1.189     0.5406      1.171          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:31<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.986      0.898      0.952       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100     0.209G      1.189       0.54      1.168          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:31<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.975      0.909       0.95       0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100     0.209G      1.185     0.5339      1.163          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:30<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.97      0.912      0.952      0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100     0.209G      1.175      0.528      1.167          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:30<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.977      0.913      0.953      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100     0.209G      1.173     0.5263       1.16          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:31<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.974      0.902      0.949      0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100     0.209G       1.17     0.5284      1.157          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:31<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979      0.908      0.951      0.631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100     0.209G      1.162     0.5252      1.155          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:33<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.969      0.907      0.948      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100     0.209G      1.168     0.5221      1.159          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:31<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.968      0.909      0.951      0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100     0.209G      1.154      0.518       1.15          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:32<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.957      0.895      0.942      0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100     0.209G      1.161     0.5147      1.154          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:33<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.978      0.907       0.95      0.628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100     0.209G      1.157     0.5131       1.15          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.96      0.907      0.947      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100     0.209G      1.148     0.5112      1.142          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:32<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.968      0.888      0.947      0.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100     0.209G      1.149     0.5063      1.144          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:30<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.975      0.908      0.954      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100     0.209G      1.154     0.5045      1.142          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:30<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.901      0.954      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100     0.209G      1.144     0.5009      1.146          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:30<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.977      0.902       0.95      0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100     0.209G      1.143     0.5013      1.143          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:31<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.977      0.901      0.951      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100     0.209G       1.14     0.4997      1.136          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:30<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979      0.904       0.95      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100     0.209G      1.141      0.497      1.139          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:34<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979      0.903      0.951      0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100     0.209G      1.133     0.4908      1.136          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.901      0.952      0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100     0.209G      1.134      0.489      1.138          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.978      0.897       0.95      0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100     0.209G      1.135     0.4881      1.136          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.98      0.895      0.946      0.628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100     0.209G      1.125     0.4865      1.135          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.902       0.95      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100     0.209G      1.128     0.4834      1.136          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:32<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.982      0.902      0.949      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100     0.209G      1.115     0.4832      1.125          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.975      0.905      0.947      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100     0.209G       1.11      0.476      1.125          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.978      0.909       0.95      0.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100     0.209G      1.107     0.4768       1.12          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979        0.9       0.95      0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100     0.209G       1.11     0.4749      1.124          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.981      0.903      0.952      0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100     0.209G      1.106     0.4689      1.114          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.977       0.91      0.954      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100     0.209G      1.092     0.4671      1.116          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:34<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.977      0.911      0.952      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100     0.209G      1.091     0.4688      1.113          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.985      0.896      0.946      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100     0.209G      1.093     0.4674      1.112          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979      0.909      0.946      0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100     0.209G      1.078     0.4586      1.109          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.977      0.906      0.947      0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100     0.209G      1.084     0.4608      1.109          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.974      0.912      0.952      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100     0.209G       1.08     0.4594      1.107          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.976      0.906      0.949      0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100     0.209G       1.07     0.4568      1.104          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.982      0.905      0.947      0.639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100     0.209G      1.068     0.4522      1.101          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:32<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.982      0.901       0.94      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100     0.209G      1.069     0.4523        1.1          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:33<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.986      0.894      0.938      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100     0.209G      1.061     0.4483        1.1          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.982      0.888      0.934      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100     0.209G      1.058     0.4479      1.097          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.989      0.883      0.927      0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100     0.209G      1.052     0.4467      1.097          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.988      0.886       0.93       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100     0.209G      1.052     0.4431      1.093          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:32<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.986      0.892      0.935      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100     0.209G      1.044      0.441      1.093          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:33<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.893      0.934      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100     0.209G      1.041     0.4421      1.088          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.889      0.933      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100     0.209G      1.035     0.4395      1.088          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:33<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.887      0.932      0.626\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 30 epochs. Best results observed at epoch 66, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=30) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "96 epochs completed in 8.145 hours.\n",
      "Optimizer stripped from C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\models\\red_plate_memory_opt\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\models\\red_plate_memory_opt\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\models\\red_plate_memory_opt\\weights\\best.pt...\n",
      "Ultralytics 8.3.156  Python-3.12.4 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.901      0.954      0.647\n",
      "Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\models\\red_plate_memory_opt\u001b[0m\n",
      "üéâ Training completed successfully!\n",
      "üíæ Best model saved at: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\\models\\red_plate_memory_opt/weights/best.pt\n",
      "\n",
      "üîç Running validation...\n",
      "Ultralytics 8.3.156  Python-3.12.4 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 34.813.6 MB/s, size: 20.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\minhk\\Downloads\\code thu√™\\AI\\NguyenLam\\dataset\\valid\\labels.cache... 2048 images, 3 backgrounds,\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1024/1024 [0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.984      0.901      0.955      0.647\n",
      "Speed: 0.2ms preprocess, 5.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\models\\red_plate_memory_opt\u001b[0m\n",
      "üìä Validation Results:\n",
      "   mAP50: 0.9548\n",
      "   mAP50-95: 0.6471\n",
      "   Precision: 0.9836\n",
      "   Recall: 0.9007\n",
      "\n",
      "‚úÖ Training successful! Model saved at: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\\models\\red_plate_memory_opt\n",
      "üìÅ Best weights: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\\models\\red_plate_memory_opt/weights/best.pt\n",
      "üìÅ Last weights: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\\models\\red_plate_memory_opt/weights/last.pt\n",
      "üìÅ Training results: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\\models\\red_plate_memory_opt\n",
      "\n",
      "üìÇ Directory structure:\n",
      "   C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset/\n",
      "   ‚îú‚îÄ‚îÄ models/\n",
      "   ‚îÇ   ‚îî‚îÄ‚îÄ red_plate_memory_opt/\n",
      "   ‚îÇ       ‚îú‚îÄ‚îÄ weights/\n",
      "   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ best.pt\n",
      "   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ last.pt\n",
      "   ‚îÇ       ‚îú‚îÄ‚îÄ results.png\n",
      "   ‚îÇ       ‚îî‚îÄ‚îÄ confusion_matrix.png\n",
      "   ‚îî‚îÄ‚îÄ data.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import gc\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear GPU memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def optimize_gpu_memory():\n",
    "    \"\"\"Optimize GPU memory settings\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        # Set memory allocation strategy\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "        \n",
    "        # Clear cache\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Get GPU info\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"üñ•Ô∏è  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"üíæ Total GPU Memory: {gpu_memory:.1f} GB\")\n",
    "        \n",
    "        # Calculate optimal batch size for different GPU memory sizes\n",
    "        if gpu_memory <= 4:\n",
    "            recommended_batch = 2\n",
    "            recommended_workers = 2\n",
    "        elif gpu_memory <= 6:\n",
    "            recommended_batch = 4\n",
    "            recommended_workers = 4\n",
    "        elif gpu_memory <= 8:\n",
    "            recommended_batch = 8\n",
    "            recommended_workers = 6\n",
    "        else:\n",
    "            recommended_batch = 16\n",
    "            recommended_workers = 8\n",
    "            \n",
    "        return recommended_batch, recommended_workers\n",
    "    else:\n",
    "        return 4, 2  # CPU fallback\n",
    "\n",
    "def train_memory_optimized():\n",
    "    print(\"üî¥ Memory-Optimized YOLOv8 Red License Plate Training\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Clear memory first\n",
    "    clear_memory()\n",
    "    \n",
    "    # Optimize memory settings\n",
    "    batch_size, workers = optimize_gpu_memory()\n",
    "    \n",
    "    # Dataset path\n",
    "    dataset_path = \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\"\n",
    "    \n",
    "    # Create models directory in dataset path\n",
    "    models_dir = os.path.join(dataset_path, \"models\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    # Use smaller model for limited GPU memory\n",
    "    print(\"ü§ñ Using YOLOv8n (Nano) for memory efficiency...\")\n",
    "    model = YOLO('yolov8n.pt')\n",
    "    \n",
    "    # Memory-optimized training configuration\n",
    "    train_config = {\n",
    "        'data': f'{dataset_path}/data.yaml',\n",
    "        'epochs': 100,\n",
    "        'imgsz': 416,\n",
    "        'batch': batch_size,\n",
    "        'name': 'red_plate_memory_opt',\n",
    "        'patience': 30,\n",
    "        'save': True,\n",
    "        'plots': True,\n",
    "        'device': 0 if torch.cuda.is_available() else 'cpu',\n",
    "        'workers': workers,\n",
    "        'project': models_dir,  # Changed to save in dataset/models\n",
    "        'exist_ok': True,\n",
    "        \n",
    "        # Memory optimization\n",
    "        'amp': True,\n",
    "        'fraction': 0.9,\n",
    "        'cache': False,\n",
    "        'rect': True,\n",
    "        'resume': False,\n",
    "        'single_cls': False,\n",
    "        \n",
    "        # Learning rate parameters\n",
    "        'lr0': 0.005,\n",
    "        'lrf': 0.1,\n",
    "        'momentum': 0.937,\n",
    "        'weight_decay': 0.0005,\n",
    "        'warmup_epochs': 2,\n",
    "        'warmup_momentum': 0.8,\n",
    "        'warmup_bias_lr': 0.1,\n",
    "        \n",
    "        # Loss weights\n",
    "        'box': 7.5,\n",
    "        'cls': 0.5,\n",
    "        'dfl': 1.5,\n",
    "        \n",
    "        # Data augmentation parameters\n",
    "        'hsv_h': 0.01,\n",
    "        'hsv_s': 0.5,\n",
    "        'hsv_v': 0.3,\n",
    "        'degrees': 0.0,\n",
    "        'translate': 0.05,\n",
    "        'scale': 0.3,\n",
    "        'shear': 0.0,\n",
    "        'perspective': 0.0,\n",
    "        'flipud': 0.0,\n",
    "        'fliplr': 0.5,\n",
    "        'mosaic': 0.5,\n",
    "        'mixup': 0.0,\n",
    "        'copy_paste': 0.0\n",
    "    }\n",
    "    \n",
    "    print(\"üìã Memory-Optimized Configuration:\")\n",
    "    print(f\"   Image size: {train_config['imgsz']}\")\n",
    "    print(f\"   Batch size: {train_config['batch']}\")\n",
    "    print(f\"   Workers: {train_config['workers']}\")\n",
    "    print(f\"   AMP enabled: {train_config['amp']}\")\n",
    "    print(f\"   Models will be saved to: {models_dir}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Clear memory before training\n",
    "        clear_memory()\n",
    "        \n",
    "        # Start training\n",
    "        print(\"üöÄ Starting memory-optimized training...\")\n",
    "        results = model.train(**train_config)\n",
    "        \n",
    "        print(\"üéâ Training completed successfully!\")\n",
    "        \n",
    "        # Get the actual save directory\n",
    "        save_dir = os.path.join(models_dir, 'red_plate_memory_opt')\n",
    "        print(f\"üíæ Best model saved at: {save_dir}/weights/best.pt\")\n",
    "        \n",
    "        # Clear memory after training\n",
    "        clear_memory()\n",
    "        \n",
    "        # Quick validation\n",
    "        print(\"\\nüîç Running validation...\")\n",
    "        metrics = model.val()\n",
    "        \n",
    "        print(\"üìä Validation Results:\")\n",
    "        if hasattr(metrics, 'box'):\n",
    "            print(f\"   mAP50: {metrics.box.map50:.4f}\")\n",
    "            print(f\"   mAP50-95: {metrics.box.map:.4f}\")\n",
    "            print(f\"   Precision: {metrics.box.mp:.4f}\")\n",
    "            print(f\"   Recall: {metrics.box.mr:.4f}\")\n",
    "        else:\n",
    "            print(\"   Validation metrics computed successfully\")\n",
    "        \n",
    "        return save_dir\n",
    "        \n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        print(\"‚ùå Still out of memory! Trying CPU training...\")\n",
    "        clear_memory()\n",
    "        return train_on_cpu()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def train_on_cpu():\n",
    "    \"\"\"Fallback to CPU training\"\"\"\n",
    "    print(\"üñ•Ô∏è  Fallback: Training on CPU...\")\n",
    "    \n",
    "    dataset_path = \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\"\n",
    "    \n",
    "    # Create models directory in dataset path\n",
    "    models_dir = os.path.join(dataset_path, \"models\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    model = YOLO('yolov8n.pt')\n",
    "    \n",
    "    # CPU-optimized configuration\n",
    "    cpu_config = {\n",
    "        'data': f'{dataset_path}/data.yaml',\n",
    "        'epochs': 50,\n",
    "        'imgsz': 320,\n",
    "        'batch': 4,\n",
    "        'name': 'red_plate_cpu',\n",
    "        'patience': 20,\n",
    "        'save': True,\n",
    "        'plots': True,\n",
    "        'device': 'cpu',\n",
    "        'workers': 2,\n",
    "        'project': models_dir,  # Changed to save in dataset/models\n",
    "        'exist_ok': True,\n",
    "        \n",
    "        # Minimal augmentation\n",
    "        'hsv_h': 0.01,\n",
    "        'hsv_s': 0.3,\n",
    "        'hsv_v': 0.2,\n",
    "        'degrees': 0.0,\n",
    "        'translate': 0.02,\n",
    "        'scale': 0.2,\n",
    "        'fliplr': 0.5,\n",
    "        'mosaic': 0.3,\n",
    "        'mixup': 0.0,\n",
    "        'copy_paste': 0.0\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        results = model.train(**cpu_config)\n",
    "        print(\"üéâ CPU training completed!\")\n",
    "        \n",
    "        # Get save directory\n",
    "        save_dir = os.path.join(models_dir, 'red_plate_cpu')\n",
    "        return save_dir\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå CPU training also failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def ultra_minimal_training():\n",
    "    \"\"\"Ultra minimal config for very limited resources\"\"\"\n",
    "    print(\"üî¨ Ultra Minimal Training for Limited Resources\")\n",
    "    \n",
    "    dataset_path = \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\"\n",
    "    \n",
    "    # Create models directory in dataset path\n",
    "    models_dir = os.path.join(dataset_path, \"models\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    # Clear all memory\n",
    "    clear_memory()\n",
    "    \n",
    "    model = YOLO('yolov8n.pt')\n",
    "    \n",
    "    minimal_config = {\n",
    "        'data': f'{dataset_path}/data.yaml',\n",
    "        'epochs': 30,\n",
    "        'imgsz': 256,\n",
    "        'batch': 1,\n",
    "        'name': 'red_plate_minimal',\n",
    "        'patience': 15,\n",
    "        'save': True,\n",
    "        'plots': False,\n",
    "        'device': 0 if torch.cuda.is_available() else 'cpu',\n",
    "        'workers': 0,\n",
    "        'project': models_dir,  # Changed to save in dataset/models\n",
    "        'exist_ok': True,\n",
    "        'cache': False,\n",
    "        'amp': True,\n",
    "        'fraction': 0.8,\n",
    "        \n",
    "        # No augmentation\n",
    "        'hsv_h': 0.0,\n",
    "        'hsv_s': 0.0,\n",
    "        'hsv_v': 0.0,\n",
    "        'degrees': 0.0,\n",
    "        'translate': 0.0,\n",
    "        'scale': 0.0,\n",
    "        'fliplr': 0.0,\n",
    "        'mosaic': 0.0,\n",
    "        'mixup': 0.0,\n",
    "        'copy_paste': 0.0\n",
    "    }\n",
    "    \n",
    "    print(\"‚ö° Ultra minimal configuration:\")\n",
    "    print(f\"   Image size: {minimal_config['imgsz']}\")\n",
    "    print(f\"   Batch size: {minimal_config['batch']}\")\n",
    "    print(f\"   Epochs: {minimal_config['epochs']}\")\n",
    "    print(f\"   Models will be saved to: {models_dir}\")\n",
    "    \n",
    "    try:\n",
    "        results = model.train(**minimal_config)\n",
    "        print(\"üéâ Ultra minimal training completed!\")\n",
    "        \n",
    "        # Get save directory\n",
    "        save_dir = os.path.join(models_dir, 'red_plate_minimal')\n",
    "        return save_dir\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Even minimal training failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def download_pretrained_models(dataset_path):\n",
    "    \"\"\"Download and save YOLO pretrained models to dataset directory\"\"\"\n",
    "    models_dir = os.path.join(dataset_path, \"pretrained_models\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"üì• Downloading pretrained models...\")\n",
    "    \n",
    "    # List of YOLO models to download\n",
    "    models = ['yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt']\n",
    "    \n",
    "    for model_name in models:\n",
    "        try:\n",
    "            print(f\"   Downloading {model_name}...\")\n",
    "            model = YOLO(model_name)\n",
    "            \n",
    "            # Save model to our directory\n",
    "            model_path = os.path.join(models_dir, model_name)\n",
    "            torch.save(model.model.state_dict(), model_path.replace('.pt', '_weights.pt'))\n",
    "            print(f\"   ‚úÖ {model_name} saved to {models_dir}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Failed to download {model_name}: {str(e)}\")\n",
    "    \n",
    "    return models_dir\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set environment variable for memory optimization\n",
    "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "    \n",
    "    # Dataset path\n",
    "    dataset_path = \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\"\n",
    "    \n",
    "    print(\"Choose training mode:\")\n",
    "    print(\"1. Memory Optimized (Recommended)\")\n",
    "    print(\"2. CPU Training\")\n",
    "    print(\"3. Ultra Minimal\")\n",
    "    print(\"4. Download Pretrained Models Only\")\n",
    "    \n",
    "    choice = input(\"Enter choice (1/2/3/4) [default: 1]: \").strip()\n",
    "    \n",
    "    if choice == \"4\":\n",
    "        models_dir = download_pretrained_models(dataset_path)\n",
    "        print(f\"\\n‚úÖ Pretrained models downloaded to: {models_dir}\")\n",
    "    elif choice == \"2\":\n",
    "        save_dir = train_on_cpu()\n",
    "    elif choice == \"3\":\n",
    "        save_dir = ultra_minimal_training()\n",
    "    else:\n",
    "        save_dir = train_memory_optimized()\n",
    "    \n",
    "    if choice != \"4\":\n",
    "        if save_dir:\n",
    "            print(f\"\\n‚úÖ Training successful! Model saved at: {save_dir}\")\n",
    "            print(f\"üìÅ Best weights: {save_dir}/weights/best.pt\")\n",
    "            print(f\"üìÅ Last weights: {save_dir}/weights/last.pt\")\n",
    "            print(f\"üìÅ Training results: {save_dir}\")\n",
    "            \n",
    "            # Show directory structure\n",
    "            print(f\"\\nüìÇ Directory structure:\")\n",
    "            print(f\"   {dataset_path}/\")\n",
    "            print(f\"   ‚îú‚îÄ‚îÄ models/\")\n",
    "            print(f\"   ‚îÇ   ‚îî‚îÄ‚îÄ {os.path.basename(save_dir)}/\")\n",
    "            print(f\"   ‚îÇ       ‚îú‚îÄ‚îÄ weights/\")\n",
    "            print(f\"   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ best.pt\")\n",
    "            print(f\"   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ last.pt\")\n",
    "            print(f\"   ‚îÇ       ‚îú‚îÄ‚îÄ results.png\")\n",
    "            print(f\"   ‚îÇ       ‚îî‚îÄ‚îÄ confusion_matrix.png\")\n",
    "            print(f\"   ‚îî‚îÄ‚îÄ data.yaml\")\n",
    "            \n",
    "        else:\n",
    "            print(\"\\n‚ùå All training attempts failed. Consider:\")\n",
    "            print(\"   - Using a machine with more GPU memory\")\n",
    "            print(\"   - Training on Google Colab with GPU\")\n",
    "            print(\"   - Using cloud training services\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b73cf80-708d-41fd-a5b1-3e44d5599211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî§ OCR Character Recognition Training\n",
      "Choose training mode:\n",
      "1. Memory Optimized (Recommended)\n",
      "2. CPU Training\n",
      "3. Ultra Minimal\n",
      "4. Test Trained Model\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter choice (1/2/3/4) [default: 1]:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî§ Memory-Optimized YOLOv8 OCR Character Recognition Training\n",
      "======================================================================\n",
      "üñ•Ô∏è  GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "üíæ Total GPU Memory: 4.0 GB\n",
      "ü§ñ Found pretrained model: yolo11n.pt\n",
      "ü§ñ Loading local model: yolo11n.pt\n",
      "üìã OCR Character Recognition Configuration:\n",
      "   Image size: 640\n",
      "   Batch size: 4\n",
      "   Workers: 2\n",
      "   Epochs: 150\n",
      "   Classes: 36 (0-9, A-Z)\n",
      "   AMP enabled: True\n",
      "   Models will be saved to: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr\\models\n",
      "======================================================================\n",
      "üöÄ Starting OCR character recognition training...\n",
      "New https://pypi.org/project/ultralytics/8.3.158 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.156  Python-3.12.4 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.1, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/minhk/Downloads/code thu/AI/NguyenLam/datasetocr/data.yaml, degrees=2.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=True, fliplr=0.0, flipud=0.0, format=torchscript, fraction=0.9, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:/Users/minhk/Downloads/code thu/AI/NguyenLam/datasetocr\\yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=ocr_character_recognition, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=50, perspective=0.0001, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/minhk/Downloads/code thu/AI/NguyenLam/datasetocr\\models, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\datasetocr\\models\\ocr_character_recognition, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=2.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=36\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    437692  ultralytics.nn.modules.head.Detect           [36, [64, 128, 256]]          \n",
      "YOLO11n summary: 181 layers, 2,596,860 parameters, 2,596,844 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 13.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 3.51.1 MB/s, size: 24.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\minhk\\Downloads\\code thu√™\\AI\\NguyenLam\\datasetocr\\labels\\train... 2759 images, 1 backgrounds, \u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\datasetocr\\images\\train\\ndata148.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\datasetocr\\images\\train\\ndata301.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\datasetocr\\labels\\train.cache\n",
      "WARNING 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 3.31.1 MB/s, size: 21.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\minhk\\Downloads\\code thu√™\\AI\\NguyenLam\\datasetocr\\labels\\val... 767 images, 2 backgrounds, 0 cor\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\datasetocr\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\datasetocr\\models\\ocr_character_recognition\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00025, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\datasetocr\\models\\ocr_character_recognition\u001b[0m\n",
      "Starting training for 150 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/150     0.666G      1.095      3.528      1.076         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:32<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.927      0.266      0.302      0.197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/150     0.824G      1.092      1.937      1.101         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:21<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.876      0.386      0.491      0.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/150     0.824G      1.096      1.339       1.11         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.748      0.591      0.682      0.496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/150     0.824G      1.088      1.092        1.1         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.699      0.772       0.78      0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/150     0.824G      1.074     0.9532      1.092         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.827      0.802      0.856      0.633\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/150     0.824G      1.041     0.8464       1.07         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.862      0.854       0.91      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/150     0.824G      1.052     0.7942      1.078         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:13<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236        0.9      0.866      0.924      0.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/150     0.824G      1.034     0.7578      1.068         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.899      0.903      0.945      0.684\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/150     0.824G      1.023     0.7283      1.063         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.911      0.905       0.95        0.7\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/150     0.824G      1.007     0.6933      1.056         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.913      0.929      0.955      0.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/150     0.824G      1.005     0.6661       1.05         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.932      0.943      0.965      0.711\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/150     0.824G     0.9957     0.6445      1.048         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.935      0.924      0.963      0.713\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/150     0.824G      0.993     0.6252      1.047         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236       0.96      0.929       0.97      0.715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/150     0.824G     0.9915     0.6116       1.05         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.957      0.925      0.969      0.712\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/150     0.824G     0.9884     0.6034      1.049         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.952      0.951      0.971      0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/150     0.824G      0.989     0.5962      1.047         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:19<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.957      0.949      0.973      0.712\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/150     0.824G     0.9831     0.5817      1.046         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:17<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.962      0.955      0.974      0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/150     0.824G     0.9826     0.5797      1.041         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:18<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236       0.95      0.947      0.976      0.719\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/150     0.824G     0.9735     0.5628      1.037         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.963      0.955      0.976      0.714\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/150     0.824G     0.9636     0.5559      1.041         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.959      0.951      0.975      0.717\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/150     0.824G      0.963     0.5429      1.038         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.957      0.956      0.976      0.717\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/150     0.824G     0.9686     0.5402      1.039         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.968       0.95      0.976       0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/150     0.824G     0.9659     0.5346      1.041         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236       0.97      0.953      0.976      0.719\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/150     0.824G      0.963     0.5315      1.035         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.965      0.958      0.977      0.718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/150     0.824G     0.9601     0.5259      1.038         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.957      0.954      0.974      0.715\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/150     0.824G     0.9573     0.5212      1.036         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.965      0.958      0.975      0.726\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/150     0.824G     0.9632     0.5138      1.039         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.969      0.954      0.976      0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/150     0.824G     0.9536     0.5009      1.029         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236       0.96      0.953      0.976      0.725\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/150     0.824G     0.9586     0.4995      1.035         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.968      0.959      0.977      0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/150     0.824G     0.9596     0.5008      1.035         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.959      0.958      0.976      0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/150     0.824G     0.9493     0.4945      1.028         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.961      0.957      0.975      0.726\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/150     0.824G     0.9574     0.4877       1.03         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.958      0.956      0.976      0.731\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/150     0.824G     0.9597      0.492      1.032         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.948       0.94      0.972      0.728\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/150     0.824G     0.9506     0.4822       1.03         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.966      0.961      0.977      0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/150     0.824G     0.9604     0.4837      1.031         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:18<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.959      0.954      0.973      0.728\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/150     0.824G     0.9628     0.4812      1.037         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.947      0.955      0.973      0.731\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/150     0.824G     0.9605     0.4774      1.032         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.954      0.958      0.974      0.732\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/150     0.824G     0.9623     0.4777      1.036         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:18<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.962      0.963      0.974      0.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/150     0.824G       0.97     0.4787      1.035         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.966      0.954      0.974       0.73\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/150     0.824G     0.9667     0.4786      1.039         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.962       0.96      0.976      0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/150     0.824G     0.9654     0.4683      1.041         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.968      0.958      0.976      0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/150     0.824G      0.972     0.4681      1.043         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:18<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236       0.95      0.956      0.973      0.728\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/150     0.824G     0.9607      0.464      1.039         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.966       0.96       0.97      0.723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/150     0.824G     0.9506     0.4574       1.03         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.971      0.951      0.974      0.731\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/150     0.824G     0.9506      0.459      1.029         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.958      0.961      0.975      0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/150     0.824G     0.9494      0.454      1.034         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:18<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.957      0.959      0.973      0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/150     0.824G     0.9513     0.4476      1.033         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.961      0.958      0.973      0.733\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/150     0.824G     0.9462     0.4461      1.035         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.955      0.953      0.973      0.732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/150     0.824G      0.953     0.4443      1.038         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:18<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.961      0.949      0.974      0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/150     0.824G      0.955     0.4432      1.037         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236       0.95      0.957      0.971      0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/150     0.824G     0.9492      0.442      1.033         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:23<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.968      0.954      0.974      0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/150     0.824G      0.949     0.4408      1.034         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.957      0.958      0.973      0.729\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/150     0.824G     0.9419     0.4363      1.033         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.961      0.949      0.974      0.733\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/150     0.824G     0.9582     0.4429      1.035         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.959      0.954      0.972      0.731\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/150     0.824G     0.9547     0.4364      1.038         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236       0.96      0.956      0.975       0.73\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/150     0.824G     0.9539     0.4378      1.037         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.961      0.954      0.973      0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/150     0.824G     0.9485     0.4263      1.037         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.966      0.959      0.976       0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/150     0.824G     0.9542     0.4292      1.038         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:13<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.961      0.952      0.973      0.723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/150     0.824G     0.9498     0.4294      1.037         25        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.954       0.95      0.973      0.724\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/150     0.824G     0.9498     0.4295      1.035         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.955      0.952      0.972      0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/150     0.824G     0.9406     0.4232      1.033         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.956      0.955      0.975      0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/150     0.824G     0.9389     0.4251      1.034         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.947      0.952      0.971       0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/150     0.824G     0.9341       0.42      1.027         25        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.951      0.948      0.969      0.724\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/150     0.824G     0.9211     0.4106      1.021         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.951      0.952      0.974      0.733\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/150     0.824G     0.9232     0.4126      1.025         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.956      0.944      0.971      0.729\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/150     0.824G     0.9302     0.4131      1.026         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.954       0.94      0.973      0.729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/150     0.824G     0.9384     0.4141      1.033         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236       0.94      0.946      0.966      0.717\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/150     0.824G     0.9337     0.4111      1.032         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.954      0.953      0.972      0.728\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/150     0.824G     0.9235     0.4081      1.026         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.945      0.957      0.973      0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/150     0.824G      0.907     0.4015       1.02         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.957      0.939      0.973      0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/150     0.824G     0.8984     0.3982      1.016         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.955      0.954      0.975      0.735\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/150     0.824G     0.9016     0.3999       1.02         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.958      0.952      0.976      0.735\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/150     0.824G     0.9103     0.3996       1.02         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.964      0.955      0.978      0.732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/150     0.824G     0.9119     0.3983      1.027         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.957      0.944      0.971      0.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/150     0.824G     0.9122     0.3968      1.024         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.953      0.954      0.971      0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/150     0.824G     0.9034     0.3942      1.018         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.967      0.935      0.965      0.723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/150     0.824G     0.9051     0.3974      1.018         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.943      0.947       0.97      0.723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/150     0.824G     0.8946       0.39      1.014         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:18<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.952      0.948       0.97      0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/150     0.824G     0.8898      0.389      1.011         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.936      0.954      0.967       0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/150     0.824G     0.8862     0.3858      1.014         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:09"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.955       0.95      0.971       0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/150     0.824G     0.8956     0.3887      1.016         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:24<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.959      0.946      0.968      0.724\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/150     0.824G      0.888     0.3858      1.016         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.955      0.951      0.969      0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/150     0.824G     0.8875     0.3831      1.011         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.953      0.928      0.965      0.718\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/150     0.824G     0.8944     0.3853      1.016         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.961       0.94      0.968      0.717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/150     0.824G      0.888     0.3836      1.012         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.954      0.944      0.969      0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/150     0.824G      0.885      0.381      1.011         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.962      0.941      0.969      0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/150     0.824G      0.872      0.376      1.003         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.949       0.94      0.964      0.723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/150     0.824G     0.8641     0.3737      1.006         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.954      0.948      0.968      0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/150     0.824G     0.8745     0.3742      1.007         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.953      0.941      0.966      0.716\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/150     0.824G     0.8914     0.3801      1.015         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.954      0.949      0.969      0.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/150     0.824G     0.8901      0.381      1.015         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.944      0.947      0.968      0.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/150     0.824G     0.8803     0.3763      1.009         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:18<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236       0.95      0.948      0.967      0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/150     0.824G     0.8523      0.368      0.999         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:17<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.955       0.94      0.968      0.724\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/150     0.824G      0.857     0.3678     0.9999         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.954      0.943      0.966      0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/150     0.824G     0.8568     0.3676     0.9997         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.947      0.948      0.965      0.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/150     0.824G      0.858     0.3675          1         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.959      0.941      0.966      0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/150     0.824G     0.8639     0.3667      1.005         25        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:14<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.944      0.949      0.966      0.718\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/150     0.824G     0.8782     0.3723      1.011         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.942      0.954      0.966      0.711\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/150     0.824G     0.8553      0.365      1.001         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:18<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.958       0.94      0.966      0.719\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/150     0.824G      0.838     0.3608     0.9933         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.959      0.946      0.967      0.725\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    101/150     0.824G     0.8283     0.3556     0.9884         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236       0.96      0.944      0.968      0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    102/150     0.824G     0.8419     0.3589     0.9936         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:17<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.956      0.945      0.969      0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    103/150     0.824G     0.8557     0.3612      1.005         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.943      0.943      0.964      0.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    104/150     0.824G     0.8537     0.3615      1.002         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.948      0.946       0.96      0.717\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    105/150     0.824G     0.8324      0.354       0.99         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.956      0.937      0.963       0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    106/150     0.824G     0.8191     0.3515     0.9915         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.952      0.937      0.963      0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    107/150     0.824G      0.814     0.3473     0.9832         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.951      0.942      0.966      0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    108/150     0.824G     0.8222     0.3504     0.9865         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.949      0.949      0.967       0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    109/150     0.824G     0.8274     0.3498     0.9921         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.955      0.944      0.966      0.717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    110/150     0.824G     0.8219     0.3499     0.9889         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.941       0.95      0.965      0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    111/150     0.824G     0.8108     0.3458     0.9783         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.952      0.945      0.968      0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    112/150     0.824G     0.8069     0.3428     0.9815         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.959      0.943      0.967      0.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    113/150     0.824G     0.7972     0.3419     0.9767         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:15<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236       0.96      0.942      0.969      0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    114/150     0.824G     0.7954     0.3408     0.9752         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.953      0.943      0.968      0.718\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    115/150     0.824G     0.8098     0.3452     0.9811         26        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.951      0.944      0.968      0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    116/150     0.824G     0.8017      0.343     0.9766         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.953      0.945      0.968      0.715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    117/150     0.824G     0.7954     0.3418     0.9747         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.953      0.937      0.968      0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    118/150     0.824G     0.7823     0.3373     0.9745         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:17<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.952      0.948      0.967       0.72\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    119/150     0.824G     0.7844     0.3378       0.97         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:16<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.956      0.942      0.965      0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    120/150     0.824G     0.7869     0.3373     0.9741         27        480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 690/690 [01:19<00:00,  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.951      0.947      0.967      0.715\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 50 epochs. Best results observed at epoch 70, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=50) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "120 epochs completed in 2.820 hours.\n",
      "Optimizer stripped from C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\datasetocr\\models\\ocr_character_recognition\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\datasetocr\\models\\ocr_character_recognition\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\datasetocr\\models\\ocr_character_recognition\\weights\\best.pt...\n",
      "Ultralytics 8.3.156  Python-3.12.4 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,589,172 parameters, 0 gradients, 6.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.957      0.939      0.973      0.736\n",
      "                     0        529        836       0.98      0.972      0.982       0.64\n",
      "                     1        408        541       0.96      0.993      0.993      0.767\n",
      "                     2        328        423       0.99      0.979      0.994      0.768\n",
      "                     3        330        425      0.959      0.988      0.985      0.705\n",
      "                     4        523        754      0.976      0.988       0.99      0.778\n",
      "                     5        328        428      0.968      0.988      0.988      0.763\n",
      "                     6        314        418      0.969       0.99      0.988       0.74\n",
      "                     7        287        373      0.969      0.981      0.986      0.745\n",
      "                     8        459        630      0.989      0.987      0.994      0.782\n",
      "                     9         61         64      0.968      0.961      0.985      0.687\n",
      "                     A        150        153      0.942      0.948      0.962      0.751\n",
      "                     B         52         52          1      0.845      0.965       0.74\n",
      "                     C         54         56      0.892      0.857      0.896       0.67\n",
      "                     D         40         40      0.968          1      0.995      0.783\n",
      "                     E         72         72      0.967          1      0.995       0.76\n",
      "                     F         64         68          1      0.933      0.993      0.695\n",
      "                     G         39         39      0.965      0.897      0.969      0.791\n",
      "                     H         33         34      0.994      0.882      0.956      0.683\n",
      "                     I         41         42      0.999      0.952      0.992      0.726\n",
      "                     J         56         60      0.849       0.94      0.942      0.702\n",
      "                     K         22         22      0.847      0.864      0.896      0.708\n",
      "                     L         34         34      0.943      0.971      0.992      0.783\n",
      "                     M         40         40      0.986          1      0.995      0.721\n",
      "                     N         33         33          1      0.918      0.975       0.77\n",
      "                     O         31         31      0.923          1       0.99      0.783\n",
      "                     P         17         17      0.879      0.858      0.947       0.71\n",
      "                     Q         26         26      0.947          1      0.995      0.729\n",
      "                     R          9          9      0.932      0.889       0.89      0.707\n",
      "                     S         50         55          1      0.605      0.978      0.719\n",
      "                     T        358        461      0.934      0.987      0.982       0.76\n",
      "Speed: 0.2ms preprocess, 2.7ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\datasetocr\\models\\ocr_character_recognition\u001b[0m\n",
      "üéâ Training completed successfully!\n",
      "üíæ Best model saved at: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr\\models\\ocr_character_recognition/weights/best.pt\n",
      "\n",
      "üîç Running validation...\n",
      "Ultralytics 8.3.156  Python-3.12.4 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,589,172 parameters, 0 gradients, 6.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 265.9167.4 MB/s, size: 47.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\minhk\\Downloads\\code thu√™\\AI\\NguyenLam\\datasetocr\\labels\\val.cache... 767 images, 2 backgrounds,\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 192/192 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        767       6236      0.956      0.938      0.973      0.735\n",
      "                     0        529        836       0.98      0.972      0.982      0.643\n",
      "                     1        408        541      0.959      0.993      0.992      0.765\n",
      "                     2        328        423       0.99      0.981      0.994       0.77\n",
      "                     3        330        425      0.955      0.988      0.985      0.703\n",
      "                     4        523        754      0.977      0.988      0.991      0.778\n",
      "                     5        328        428       0.97      0.988      0.988      0.764\n",
      "                     6        314        418      0.972       0.99      0.988      0.741\n",
      "                     7        287        373      0.969      0.981      0.986      0.747\n",
      "                     8        459        630       0.99      0.987      0.994      0.782\n",
      "                     9         61         64      0.968      0.946      0.985      0.695\n",
      "                     A        150        153      0.937      0.948      0.962      0.755\n",
      "                     B         52         52          1      0.845      0.962      0.742\n",
      "                     C         54         56      0.892      0.857      0.897      0.671\n",
      "                     D         40         40      0.968          1      0.995      0.782\n",
      "                     E         72         72      0.967          1      0.995      0.758\n",
      "                     F         64         68      0.993      0.926      0.992      0.694\n",
      "                     G         39         39      0.965      0.897      0.969      0.778\n",
      "                     H         33         34      0.994      0.882      0.956      0.679\n",
      "                     I         41         42      0.999      0.952      0.992      0.727\n",
      "                     J         56         60       0.85      0.941      0.936      0.699\n",
      "                     K         22         22      0.847      0.864      0.896        0.7\n",
      "                     L         34         34      0.943      0.971      0.992      0.785\n",
      "                     M         40         40      0.986          1      0.995      0.729\n",
      "                     N         33         33          1      0.918      0.975      0.772\n",
      "                     O         31         31      0.922          1       0.99      0.787\n",
      "                     P         17         17      0.879      0.858      0.947      0.708\n",
      "                     Q         26         26      0.947          1      0.995      0.718\n",
      "                     R          9          9      0.931      0.889       0.89      0.696\n",
      "                     S         50         55          1      0.588      0.985      0.719\n",
      "                     T        358        461      0.935      0.987      0.982       0.76\n",
      "Speed: 0.3ms preprocess, 6.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\datasetocr\\models\\ocr_character_recognition\u001b[0m\n",
      "üìä Validation Results:\n",
      "   mAP50: 0.9729\n",
      "   mAP50-95: 0.7349\n",
      "   Precision: 0.9562\n",
      "   Recall: 0.9380\n",
      "\n",
      "‚úÖ OCR Training successful! Model saved at: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr\\models\\ocr_character_recognition\n",
      "üìÅ Best weights: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr\\models\\ocr_character_recognition/weights/best.pt\n",
      "üìÅ Last weights: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr\\models\\ocr_character_recognition/weights/last.pt\n",
      "üìÅ Training results: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr\\models\\ocr_character_recognition\n",
      "\n",
      "üìÇ Directory structure:\n",
      "   C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr/\n",
      "   ‚îú‚îÄ‚îÄ models/\n",
      "   ‚îÇ   ‚îî‚îÄ‚îÄ ocr_character_recognition/\n",
      "   ‚îÇ       ‚îú‚îÄ‚îÄ weights/\n",
      "   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ best.pt\n",
      "   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ last.pt\n",
      "   ‚îÇ       ‚îú‚îÄ‚îÄ results.png\n",
      "   ‚îÇ       ‚îî‚îÄ‚îÄ confusion_matrix.png\n",
      "   ‚îú‚îÄ‚îÄ images/\n",
      "   ‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
      "   ‚îÇ   ‚îî‚îÄ‚îÄ val/\n",
      "   ‚îú‚îÄ‚îÄ labels/\n",
      "   ‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
      "   ‚îÇ   ‚îî‚îÄ‚îÄ val/\n",
      "   ‚îî‚îÄ‚îÄ data.yaml\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Would you like to test the trained model? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\datasetocr\\images\\val\\10PlateBaza275.jpg: 384x640 1 0, 1 1, 1 2, 1 5, 1 6, 1 7, 1 9, 1 A, 1 F, 156.3ms\n",
      "Speed: 28.0ms preprocess, 156.3ms inference, 30.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "üîç Testing on: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr\\images\\val\\10PlateBaza275.jpg\n",
      "üìä Detected 9 characters:\n",
      "   1. Character: '2' (Confidence: 0.90)\n",
      "   2. Character: 'A' (Confidence: 0.90)\n",
      "   3. Character: '7' (Confidence: 0.89)\n",
      "   4. Character: '1' (Confidence: 0.84)\n",
      "   5. Character: 'F' (Confidence: 0.78)\n",
      "   6. Character: '0' (Confidence: 0.69)\n",
      "   7. Character: '9' (Confidence: 0.62)\n",
      "   8. Character: '5' (Confidence: 0.55)\n",
      "   9. Character: '6' (Confidence: 0.28)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import gc\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear GPU memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def optimize_gpu_memory():\n",
    "    \"\"\"Optimize GPU memory settings\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        # Set memory allocation strategy\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "        \n",
    "        # Clear cache\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Get GPU info\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"üñ•Ô∏è  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"üíæ Total GPU Memory: {gpu_memory:.1f} GB\")\n",
    "        \n",
    "        # Calculate optimal batch size for different GPU memory sizes\n",
    "        if gpu_memory <= 4:\n",
    "            recommended_batch = 4\n",
    "            recommended_workers = 2\n",
    "        elif gpu_memory <= 6:\n",
    "            recommended_batch = 8\n",
    "            recommended_workers = 4\n",
    "        elif gpu_memory <= 8:\n",
    "            recommended_batch = 16\n",
    "            recommended_workers = 6\n",
    "        else:\n",
    "            recommended_batch = 32\n",
    "            recommended_workers = 8\n",
    "            \n",
    "        return recommended_batch, recommended_workers\n",
    "    else:\n",
    "        return 8, 2  # CPU fallback\n",
    "\n",
    "def train_ocr_optimized():\n",
    "    print(\"üî§ Memory-Optimized YOLOv8 OCR Character Recognition Training\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Clear memory first\n",
    "    clear_memory()\n",
    "    \n",
    "    # Optimize memory settings\n",
    "    batch_size, workers = optimize_gpu_memory()\n",
    "    \n",
    "    # Dataset path - updated to match your structure\n",
    "    dataset_path = \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr\"\n",
    "    \n",
    "    # Create models directory in dataset path\n",
    "    models_dir = os.path.join(dataset_path, \"models\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    # Check if pretrained models exist in the directory\n",
    "    pretrained_models = ['yolo11n.pt', 'yolov8n.pt']\n",
    "    model_path = None\n",
    "    \n",
    "    for model_name in pretrained_models:\n",
    "        model_file = os.path.join(dataset_path, model_name)\n",
    "        if os.path.exists(model_file):\n",
    "            model_path = model_file\n",
    "            print(f\"ü§ñ Found pretrained model: {model_name}\")\n",
    "            break\n",
    "    \n",
    "    if model_path is None:\n",
    "        print(\"ü§ñ Using YOLOv8n (downloading if needed)...\")\n",
    "        model = YOLO('yolov8n.pt')\n",
    "    else:\n",
    "        print(f\"ü§ñ Loading local model: {os.path.basename(model_path)}\")\n",
    "        model = YOLO(model_path)\n",
    "    \n",
    "    # OCR-optimized training configuration\n",
    "    train_config = {\n",
    "        'data': f'{dataset_path}/data.yaml',\n",
    "        'epochs': 150,  # More epochs for character recognition\n",
    "        'imgsz': 640,   # Good resolution for character details\n",
    "        'batch': batch_size,\n",
    "        'name': 'ocr_character_recognition',\n",
    "        'patience': 50,  # More patience for character learning\n",
    "        'save': True,\n",
    "        'plots': True,\n",
    "        'device': 0 if torch.cuda.is_available() else 'cpu',\n",
    "        'workers': workers,\n",
    "        'project': models_dir,\n",
    "        'exist_ok': True,\n",
    "        \n",
    "        # Memory optimization\n",
    "        'amp': True,\n",
    "        'fraction': 0.9,\n",
    "        'cache': False,  # Set to True if you have enough RAM\n",
    "        'rect': True,\n",
    "        'resume': False,\n",
    "        'single_cls': False,\n",
    "        \n",
    "        # Learning rate parameters - optimized for character recognition\n",
    "        'lr0': 0.01,    # Higher initial learning rate for character features\n",
    "        'lrf': 0.01,    # Final learning rate\n",
    "        'momentum': 0.937,\n",
    "        'weight_decay': 0.0005,\n",
    "        'warmup_epochs': 3,\n",
    "        'warmup_momentum': 0.8,\n",
    "        'warmup_bias_lr': 0.1,\n",
    "        \n",
    "        # Loss weights - optimized for character detection\n",
    "        'box': 7.5,     # Box regression weight\n",
    "        'cls': 0.5,     # Classification weight\n",
    "        'dfl': 1.5,     # Distribution focal loss weight\n",
    "        \n",
    "        # Data augmentation - careful with characters\n",
    "        'hsv_h': 0.015,  # Small hue variation\n",
    "        'hsv_s': 0.7,    # Saturation variation\n",
    "        'hsv_v': 0.4,    # Value variation\n",
    "        'degrees': 2.0,  # Small rotation for characters\n",
    "        'translate': 0.1, # Translation\n",
    "        'scale': 0.5,    # Scale variation\n",
    "        'shear': 2.0,    # Small shear for character variation\n",
    "        'perspective': 0.0001, # Minimal perspective change\n",
    "        'flipud': 0.0,   # No vertical flip for characters\n",
    "        'fliplr': 0.0,   # No horizontal flip (would mirror characters)\n",
    "        'mosaic': 1.0,   # Mosaic augmentation\n",
    "        'mixup': 0.0,    # No mixup for character clarity\n",
    "        'copy_paste': 0.1 # Small copy-paste augmentation\n",
    "    }\n",
    "    \n",
    "    print(\"üìã OCR Character Recognition Configuration:\")\n",
    "    print(f\"   Image size: {train_config['imgsz']}\")\n",
    "    print(f\"   Batch size: {train_config['batch']}\")\n",
    "    print(f\"   Workers: {train_config['workers']}\")\n",
    "    print(f\"   Epochs: {train_config['epochs']}\")\n",
    "    print(f\"   Classes: 36 (0-9, A-Z)\")\n",
    "    print(f\"   AMP enabled: {train_config['amp']}\")\n",
    "    print(f\"   Models will be saved to: {models_dir}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    try:\n",
    "        # Clear memory before training\n",
    "        clear_memory()\n",
    "        \n",
    "        # Start training\n",
    "        print(\"üöÄ Starting OCR character recognition training...\")\n",
    "        results = model.train(**train_config)\n",
    "        \n",
    "        print(\"üéâ Training completed successfully!\")\n",
    "        \n",
    "        # Get the actual save directory\n",
    "        save_dir = os.path.join(models_dir, 'ocr_character_recognition')\n",
    "        print(f\"üíæ Best model saved at: {save_dir}/weights/best.pt\")\n",
    "        \n",
    "        # Clear memory after training\n",
    "        clear_memory()\n",
    "        \n",
    "        # Quick validation\n",
    "        print(\"\\nüîç Running validation...\")\n",
    "        metrics = model.val()\n",
    "        \n",
    "        print(\"üìä Validation Results:\")\n",
    "        if hasattr(metrics, 'box'):\n",
    "            print(f\"   mAP50: {metrics.box.map50:.4f}\")\n",
    "            print(f\"   mAP50-95: {metrics.box.map:.4f}\")\n",
    "            print(f\"   Precision: {metrics.box.mp:.4f}\")\n",
    "            print(f\"   Recall: {metrics.box.mr:.4f}\")\n",
    "        else:\n",
    "            print(\"   Validation metrics computed successfully\")\n",
    "        \n",
    "        return save_dir\n",
    "        \n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        print(\"‚ùå GPU out of memory! Trying CPU training...\")\n",
    "        clear_memory()\n",
    "        return train_ocr_on_cpu()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def train_ocr_on_cpu():\n",
    "    \"\"\"Fallback to CPU training for OCR\"\"\"\n",
    "    print(\"üñ•Ô∏è  Fallback: OCR Training on CPU...\")\n",
    "    \n",
    "    dataset_path = \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr\"\n",
    "    \n",
    "    # Create models directory in dataset path\n",
    "    models_dir = os.path.join(dataset_path, \"models\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    # Try to load local model first\n",
    "    pretrained_models = ['yolo11n.pt', 'yolov8n.pt']\n",
    "    model_path = None\n",
    "    \n",
    "    for model_name in pretrained_models:\n",
    "        model_file = os.path.join(dataset_path, model_name)\n",
    "        if os.path.exists(model_file):\n",
    "            model_path = model_file\n",
    "            break\n",
    "    \n",
    "    if model_path:\n",
    "        model = YOLO(model_path)\n",
    "    else:\n",
    "        model = YOLO('yolov8n.pt')\n",
    "    \n",
    "    # CPU-optimized configuration for OCR\n",
    "    cpu_config = {\n",
    "        'data': f'{dataset_path}/data.yaml',\n",
    "        'epochs': 100,\n",
    "        'imgsz': 480,\n",
    "        'batch': 8,\n",
    "        'name': 'ocr_character_cpu',\n",
    "        'patience': 30,\n",
    "        'save': True,\n",
    "        'plots': True,\n",
    "        'device': 'cpu',\n",
    "        'workers': 2,\n",
    "        'project': models_dir,\n",
    "        'exist_ok': True,\n",
    "        \n",
    "        # Minimal augmentation for CPU\n",
    "        'hsv_h': 0.01,\n",
    "        'hsv_s': 0.4,\n",
    "        'hsv_v': 0.3,\n",
    "        'degrees': 1.0,\n",
    "        'translate': 0.05,\n",
    "        'scale': 0.3,\n",
    "        'fliplr': 0.0,  # No flip for characters\n",
    "        'mosaic': 0.5,\n",
    "        'mixup': 0.0,\n",
    "        'copy_paste': 0.0\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        results = model.train(**cpu_config)\n",
    "        print(\"üéâ CPU OCR training completed!\")\n",
    "        \n",
    "        # Get save directory\n",
    "        save_dir = os.path.join(models_dir, 'ocr_character_cpu')\n",
    "        return save_dir\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå CPU training also failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def ultra_minimal_ocr_training():\n",
    "    \"\"\"Ultra minimal config for very limited resources\"\"\"\n",
    "    print(\"üî¨ Ultra Minimal OCR Training for Limited Resources\")\n",
    "    \n",
    "    dataset_path = \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr\"\n",
    "    \n",
    "    # Create models directory in dataset path\n",
    "    models_dir = os.path.join(dataset_path, \"models\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    # Clear all memory\n",
    "    clear_memory()\n",
    "    \n",
    "    # Try to load local model first\n",
    "    pretrained_models = ['yolo11n.pt', 'yolov8n.pt']\n",
    "    model_path = None\n",
    "    \n",
    "    for model_name in pretrained_models:\n",
    "        model_file = os.path.join(dataset_path, model_name)\n",
    "        if os.path.exists(model_file):\n",
    "            model_path = model_file\n",
    "            break\n",
    "    \n",
    "    if model_path:\n",
    "        model = YOLO(model_path)\n",
    "    else:\n",
    "        model = YOLO('yolov8n.pt')\n",
    "    \n",
    "    minimal_config = {\n",
    "        'data': f'{dataset_path}/data.yaml',\n",
    "        'epochs': 50,\n",
    "        'imgsz': 320,\n",
    "        'batch': 2,\n",
    "        'name': 'ocr_character_minimal',\n",
    "        'patience': 20,\n",
    "        'save': True,\n",
    "        'plots': False,\n",
    "        'device': 0 if torch.cuda.is_available() else 'cpu',\n",
    "        'workers': 0,\n",
    "        'project': models_dir,\n",
    "        'exist_ok': True,\n",
    "        'cache': False,\n",
    "        'amp': True,\n",
    "        'fraction': 0.8,\n",
    "        \n",
    "        # Minimal augmentation\n",
    "        'hsv_h': 0.0,\n",
    "        'hsv_s': 0.0,\n",
    "        'hsv_v': 0.0,\n",
    "        'degrees': 0.0,\n",
    "        'translate': 0.0,\n",
    "        'scale': 0.0,\n",
    "        'fliplr': 0.0,\n",
    "        'mosaic': 0.0,\n",
    "        'mixup': 0.0,\n",
    "        'copy_paste': 0.0\n",
    "    }\n",
    "    \n",
    "    print(\"‚ö° Ultra minimal OCR configuration:\")\n",
    "    print(f\"   Image size: {minimal_config['imgsz']}\")\n",
    "    print(f\"   Batch size: {minimal_config['batch']}\")\n",
    "    print(f\"   Epochs: {minimal_config['epochs']}\")\n",
    "    print(f\"   Classes: 36 (0-9, A-Z)\")\n",
    "    print(f\"   Models will be saved to: {models_dir}\")\n",
    "    \n",
    "    try:\n",
    "        results = model.train(**minimal_config)\n",
    "        print(\"üéâ Ultra minimal OCR training completed!\")\n",
    "        \n",
    "        # Get save directory\n",
    "        save_dir = os.path.join(models_dir, 'ocr_character_minimal')\n",
    "        return save_dir\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Even minimal training failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def test_model_inference(model_path, test_image_path=None):\n",
    "    \"\"\"Test the trained model on sample images\"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model not found: {model_path}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Load the trained model\n",
    "        model = YOLO(model_path)\n",
    "        \n",
    "        # Test directory\n",
    "        dataset_path = \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr\"\n",
    "        test_dir = os.path.join(dataset_path, \"images\", \"val\")\n",
    "        \n",
    "        if test_image_path and os.path.exists(test_image_path):\n",
    "            # Test specific image\n",
    "            results = model(test_image_path)\n",
    "            print(f\"üîç Testing on: {test_image_path}\")\n",
    "        elif os.path.exists(test_dir):\n",
    "            # Test on validation images\n",
    "            test_images = [f for f in os.listdir(test_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            if test_images:\n",
    "                test_image = os.path.join(test_dir, test_images[0])\n",
    "                results = model(test_image)\n",
    "                print(f\"üîç Testing on: {test_image}\")\n",
    "            else:\n",
    "                print(\"‚ùå No test images found\")\n",
    "                return\n",
    "        else:\n",
    "            print(\"‚ùå No test directory found\")\n",
    "            return\n",
    "        \n",
    "        # Display results\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            if boxes is not None:\n",
    "                print(f\"üìä Detected {len(boxes)} characters:\")\n",
    "                for i, box in enumerate(boxes):\n",
    "                    class_id = int(box.cls[0])\n",
    "                    confidence = float(box.conf[0])\n",
    "                    # Map class ID to character\n",
    "                    chars = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', \n",
    "                            'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', \n",
    "                            'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', \n",
    "                            'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "                    char = chars[class_id] if class_id < len(chars) else 'Unknown'\n",
    "                    print(f\"   {i+1}. Character: '{char}' (Confidence: {confidence:.2f})\")\n",
    "            else:\n",
    "                print(\"üìä No characters detected\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Inference failed: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set environment variable for memory optimization\n",
    "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "    \n",
    "    # Dataset path - updated for OCR\n",
    "    dataset_path = \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr\"\n",
    "    \n",
    "    print(\"üî§ OCR Character Recognition Training\")\n",
    "    print(\"Choose training mode:\")\n",
    "    print(\"1. Memory Optimized (Recommended)\")\n",
    "    print(\"2. CPU Training\")\n",
    "    print(\"3. Ultra Minimal\")\n",
    "    print(\"4. Test Trained Model\")\n",
    "    \n",
    "    choice = input(\"Enter choice (1/2/3/4) [default: 1]: \").strip()\n",
    "    \n",
    "    if choice == \"4\":\n",
    "        model_path = input(\"Enter path to trained model (best.pt): \").strip()\n",
    "        if not model_path:\n",
    "            # Try to find the latest trained model\n",
    "            models_dir = os.path.join(dataset_path, \"models\")\n",
    "            if os.path.exists(models_dir):\n",
    "                for subdir in os.listdir(models_dir):\n",
    "                    weights_dir = os.path.join(models_dir, subdir, \"weights\")\n",
    "                    best_model = os.path.join(weights_dir, \"best.pt\")\n",
    "                    if os.path.exists(best_model):\n",
    "                        model_path = best_model\n",
    "                        break\n",
    "        \n",
    "        if model_path and os.path.exists(model_path):\n",
    "            test_model_inference(model_path)\n",
    "        else:\n",
    "            print(\"‚ùå No trained model found. Please train a model first.\")\n",
    "            \n",
    "    elif choice == \"2\":\n",
    "        save_dir = train_ocr_on_cpu()\n",
    "    elif choice == \"3\":\n",
    "        save_dir = ultra_minimal_ocr_training()\n",
    "    else:\n",
    "        save_dir = train_ocr_optimized()\n",
    "    \n",
    "    if choice in [\"1\", \"2\", \"3\"]:\n",
    "        if save_dir:\n",
    "            print(f\"\\n‚úÖ OCR Training successful! Model saved at: {save_dir}\")\n",
    "            print(f\"üìÅ Best weights: {save_dir}/weights/best.pt\")\n",
    "            print(f\"üìÅ Last weights: {save_dir}/weights/last.pt\")\n",
    "            print(f\"üìÅ Training results: {save_dir}\")\n",
    "            \n",
    "            # Show directory structure\n",
    "            print(f\"\\nüìÇ Directory structure:\")\n",
    "            print(f\"   {dataset_path}/\")\n",
    "            print(f\"   ‚îú‚îÄ‚îÄ models/\")\n",
    "            print(f\"   ‚îÇ   ‚îî‚îÄ‚îÄ {os.path.basename(save_dir)}/\")\n",
    "            print(f\"   ‚îÇ       ‚îú‚îÄ‚îÄ weights/\")\n",
    "            print(f\"   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ best.pt\")\n",
    "            print(f\"   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ last.pt\")\n",
    "            print(f\"   ‚îÇ       ‚îú‚îÄ‚îÄ results.png\")\n",
    "            print(f\"   ‚îÇ       ‚îî‚îÄ‚îÄ confusion_matrix.png\")\n",
    "            print(f\"   ‚îú‚îÄ‚îÄ images/\")\n",
    "            print(f\"   ‚îÇ   ‚îú‚îÄ‚îÄ train/\")\n",
    "            print(f\"   ‚îÇ   ‚îî‚îÄ‚îÄ val/\")\n",
    "            print(f\"   ‚îú‚îÄ‚îÄ labels/\")\n",
    "            print(f\"   ‚îÇ   ‚îú‚îÄ‚îÄ train/\")\n",
    "            print(f\"   ‚îÇ   ‚îî‚îÄ‚îÄ val/\")\n",
    "            print(f\"   ‚îî‚îÄ‚îÄ data.yaml\")\n",
    "            \n",
    "            # Offer to test the model\n",
    "            test_choice = input(\"\\nüîç Would you like to test the trained model? (y/n): \").strip().lower()\n",
    "            if test_choice == 'y':\n",
    "                best_model = os.path.join(save_dir, \"weights\", \"best.pt\")\n",
    "                test_model_inference(best_model)\n",
    "            \n",
    "        else:\n",
    "            print(\"\\n‚ùå All training attempts failed. Consider:\")\n",
    "            print(\"   - Checking your data.yaml file path\")\n",
    "            print(\"   - Ensuring images and labels are properly formatted\")\n",
    "            print(\"   - Using a machine with more GPU memory\")\n",
    "            print(\"   - Training on Google Colab with GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "525995e5-636f-4447-875a-1657b38ed18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Checking EasyOCR...\n",
      "‚úÖ EasyOCR available\n",
      "\n",
      "üöó License Plate Detection & OCR System (EasyOCR Only)\n",
      "============================================================\n",
      "\n",
      "üîç Found models:\n",
      "   License Plate Model: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam\\dataset\\models\\red_plate_memory_opt\\weights\\best.pt\n",
      "üîÑ Loading models...\n",
      "‚úÖ License plate model loaded: best.pt (YOLOv8)\n",
      "üîÑ Initializing EasyOCR...\n",
      "‚úÖ EasyOCR initialized successfully\n",
      "\n",
      "üì∑ Initializing webcam...\n",
      "‚úÖ Webcam initialized successfully!\n",
      "\n",
      "üéØ Controls:\n",
      "   - Press 'q' to quit\n",
      "   - Press 's' to save current frame\n",
      "   - Press 'r' to show recent detections\n",
      "   - Press 'c' to clear detection history\n",
      "   - Press 'i' to show OCR statistics\n",
      "   - Press 'x' to reset OCR statistics\n",
      "‚úÖ Webcam released and windows closed\n",
      "\n",
      "üìä Final Session Statistics:\n",
      "   Total frames processed: 45742\n",
      "   Total detections: 10\n",
      "   Frames saved: 0\n",
      "   EasyOCR uses: 1530\n",
      "   EasyOCR success rate: 71.2%\n",
      "   EasyOCR average confidence: 0.735\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "import warnings\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "# Suppress stdout/stderr for model downloads\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "import io\n",
    "\n",
    "# Try to import both YOLOv5 and YOLOv8\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    ULTRALYTICS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    ULTRALYTICS_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è Ultralytics not available\")\n",
    "\n",
    "try:\n",
    "    import yolov5\n",
    "    YOLOV5_AVAILABLE = True\n",
    "except ImportError:\n",
    "    YOLOV5_AVAILABLE = False\n",
    "\n",
    "# EasyOCR only\n",
    "print(\"üîÑ Checking EasyOCR...\")\n",
    "try:\n",
    "    import easyocr\n",
    "    EASYOCR_AVAILABLE = True\n",
    "    print(\"‚úÖ EasyOCR available\")\n",
    "except ImportError:\n",
    "    EASYOCR_AVAILABLE = False\n",
    "    print(\"‚ùå EasyOCR not available\")\n",
    "    sys.exit(\"EasyOCR is required! Install with: pip install easyocr\")\n",
    "\n",
    "class EasyOCREngine:\n",
    "    \"\"\"Simplified OCR Engine using only EasyOCR\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.ocr_reader = None\n",
    "        self.total_uses = 0\n",
    "        self.successful_detections = 0\n",
    "        self.total_confidence = 0.0\n",
    "        self.total_time = 0.0\n",
    "        self.initialize_ocr()\n",
    "    \n",
    "    def initialize_ocr(self):\n",
    "        \"\"\"Initialize EasyOCR\"\"\"\n",
    "        print(\"üîÑ Initializing EasyOCR...\")\n",
    "        try:\n",
    "            with redirect_stdout(io.StringIO()), redirect_stderr(io.StringIO()):\n",
    "                self.ocr_reader = easyocr.Reader(['en'], gpu=torch.cuda.is_available())\n",
    "            print(\"‚úÖ EasyOCR initialized successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to initialize EasyOCR: {e}\")\n",
    "            sys.exit(\"Failed to initialize EasyOCR\")\n",
    "    \n",
    "    def preprocess_for_ocr(self, image):\n",
    "        \"\"\"Preprocess image for better OCR results\"\"\"\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "        \n",
    "        # Try different preprocessing methods\n",
    "        processed_images = [('original', gray)]\n",
    "        \n",
    "        # Gaussian blur + OTSU threshold\n",
    "        try:\n",
    "            blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "            _, thresh1 = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            processed_images.append(('otsu', thresh1))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Adaptive threshold\n",
    "        try:\n",
    "            adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "            processed_images.append(('adaptive', adaptive))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Histogram equalization\n",
    "        try:\n",
    "            equalized = cv2.equalizeHist(gray)\n",
    "            processed_images.append(('equalized', equalized))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return processed_images\n",
    "    \n",
    "    def recognize_with_easyocr(self, image):\n",
    "        \"\"\"OCR using EasyOCR\"\"\"\n",
    "        try:\n",
    "            with redirect_stdout(io.StringIO()), redirect_stderr(io.StringIO()):\n",
    "                results = self.ocr_reader.readtext(image)\n",
    "            \n",
    "            text_parts = []\n",
    "            confidences = []\n",
    "            \n",
    "            for (bbox, text, confidence) in results:\n",
    "                if confidence > 0.3:  # Filter low confidence results\n",
    "                    clean_text = ''.join(c for c in text.upper() if c.isalnum())\n",
    "                    if clean_text:\n",
    "                        text_parts.append(clean_text)\n",
    "                        confidences.append(confidence)\n",
    "            \n",
    "            final_text = ''.join(text_parts)\n",
    "            avg_confidence = np.mean(confidences) if confidences else 0\n",
    "            \n",
    "            return final_text, avg_confidence\n",
    "        \n",
    "        except Exception:\n",
    "            return \"\", 0\n",
    "    \n",
    "    def recognize_text(self, image):\n",
    "        \"\"\"Recognize text using EasyOCR with multiple preprocessing methods\"\"\"\n",
    "        start_time = time.time()\n",
    "        processed_images = self.preprocess_for_ocr(image)\n",
    "        best_result = (\"\", 0)\n",
    "        \n",
    "        # Try different preprocessing methods\n",
    "        for preprocess_name, processed_img in processed_images:\n",
    "            try:\n",
    "                text, conf = self.recognize_with_easyocr(processed_img)\n",
    "                \n",
    "                if conf > best_result[1] and len(text) >= 3:\n",
    "                    best_result = (text, conf)\n",
    "                    \n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        # Update statistics\n",
    "        processing_time = time.time() - start_time\n",
    "        self.total_uses += 1\n",
    "        self.total_time += processing_time\n",
    "        \n",
    "        if len(best_result[0]) >= 3 and best_result[1] > 0:\n",
    "            self.successful_detections += 1\n",
    "            self.total_confidence += best_result[1]\n",
    "        \n",
    "        return best_result\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get OCR statistics\"\"\"\n",
    "        avg_time = self.total_time / max(self.total_uses, 1)\n",
    "        success_rate = (self.successful_detections / max(self.total_uses, 1)) * 100\n",
    "        avg_confidence = self.total_confidence / max(self.successful_detections, 1)\n",
    "        \n",
    "        return {\n",
    "            'total_uses': self.total_uses,\n",
    "            'successful_detections': self.successful_detections,\n",
    "            'success_rate': success_rate,\n",
    "            'avg_confidence': avg_confidence,\n",
    "            'avg_time': avg_time\n",
    "        }\n",
    "    \n",
    "    def reset_stats(self):\n",
    "        \"\"\"Reset statistics\"\"\"\n",
    "        self.total_uses = 0\n",
    "        self.successful_detections = 0\n",
    "        self.total_confidence = 0.0\n",
    "        self.total_time = 0.0\n",
    "        print(\"üóëÔ∏è OCR statistics reset\")\n",
    "\n",
    "class LicensePlateDetector:\n",
    "    def __init__(self, plate_model_path):\n",
    "        self.plate_model_path = plate_model_path\n",
    "        \n",
    "        print(\"üîÑ Loading models...\")\n",
    "        \n",
    "        # Load YOLO model\n",
    "        try:\n",
    "            self.plate_model, self.plate_model_type = self.load_model(plate_model_path)\n",
    "            if self.plate_model:\n",
    "                print(f\"‚úÖ License plate model loaded: {os.path.basename(plate_model_path)} ({self.plate_model_type})\")\n",
    "            else:\n",
    "                print(f\"‚ùå Failed to load plate model: {plate_model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load plate model: {e}\")\n",
    "            self.plate_model = None\n",
    "            self.plate_model_type = None\n",
    "        \n",
    "        # Initialize EasyOCR\n",
    "        self.ocr_engine = EasyOCREngine()\n",
    "        \n",
    "        self.plate_conf_threshold = 0.3\n",
    "        self.recent_plates = deque(maxlen=10)\n",
    "        \n",
    "        # FPS tracking\n",
    "        self.fps_counter = 0\n",
    "        self.fps_start_time = time.time()\n",
    "        self.current_fps = 0\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"Load YOLO model with automatic detection\"\"\"\n",
    "        if not os.path.exists(model_path):\n",
    "            return None, None\n",
    "        \n",
    "        # Try YOLOv8 first\n",
    "        if ULTRALYTICS_AVAILABLE:\n",
    "            try:\n",
    "                model = YOLO(model_path)\n",
    "                return model, \"YOLOv8\"\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        # Try YOLOv5\n",
    "        if YOLOV5_AVAILABLE:\n",
    "            try:\n",
    "                model = yolov5.load(model_path)\n",
    "                return model, \"YOLOv5\"\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        # Try YOLOv5 from torch hub\n",
    "        try:\n",
    "            model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)\n",
    "            return model, \"YOLOv5-torch\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        return None, None\n",
    "    \n",
    "    def run_inference(self, model, model_type, image, conf_threshold):\n",
    "        \"\"\"Run inference based on model type\"\"\"\n",
    "        try:\n",
    "            if model_type == \"YOLOv5\" or model_type == \"YOLOv5-torch\":\n",
    "                results = model(image, size=640)\n",
    "                return self.parse_yolov5_results(results, conf_threshold)\n",
    "            elif model_type == \"YOLOv8\":\n",
    "                results = model(image, conf=conf_threshold, verbose=False)\n",
    "                return self.parse_yolov8_results(results)\n",
    "            else:\n",
    "                return []\n",
    "        except Exception:\n",
    "            return []\n",
    "    \n",
    "    def parse_yolov5_results(self, results, conf_threshold):\n",
    "        \"\"\"Parse YOLOv5 results\"\"\"\n",
    "        detections = []\n",
    "        df = results.pandas().xyxy[0]\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            confidence = row['confidence']\n",
    "            if confidence >= conf_threshold:\n",
    "                x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n",
    "                class_id = int(row['class'])\n",
    "                \n",
    "                detections.append({\n",
    "                    'bbox': (x1, y1, x2, y2),\n",
    "                    'confidence': confidence,\n",
    "                    'class_id': class_id\n",
    "                })\n",
    "        \n",
    "        return detections\n",
    "    \n",
    "    def parse_yolov8_results(self, results):\n",
    "        \"\"\"Parse YOLOv8 results\"\"\"\n",
    "        detections = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result.boxes is not None:\n",
    "                for box in result.boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    confidence = float(box.conf[0])\n",
    "                    class_id = int(box.cls[0])\n",
    "                    \n",
    "                    detections.append({\n",
    "                        'bbox': (x1, y1, x2, y2),\n",
    "                        'confidence': confidence,\n",
    "                        'class_id': class_id\n",
    "                    })\n",
    "        \n",
    "        return detections\n",
    "    \n",
    "    def detect_license_plates(self, frame):\n",
    "        \"\"\"Detect license plates in frame\"\"\"\n",
    "        if self.plate_model is None:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            detections = self.run_inference(\n",
    "                self.plate_model, \n",
    "                self.plate_model_type, \n",
    "                frame, \n",
    "                self.plate_conf_threshold\n",
    "            )\n",
    "            \n",
    "            plates = []\n",
    "            for detection in detections:\n",
    "                x1, y1, x2, y2 = detection['bbox']\n",
    "                confidence = detection['confidence']\n",
    "                \n",
    "                # Add padding to the bounding box\n",
    "                h, w = frame.shape[:2]\n",
    "                pad = 5\n",
    "                x1 = max(0, x1 - pad)\n",
    "                y1 = max(0, y1 - pad)\n",
    "                x2 = min(w, x2 + pad)\n",
    "                y2 = min(h, y2 + pad)\n",
    "                \n",
    "                plate_roi = frame[y1:y2, x1:x2]\n",
    "                \n",
    "                plates.append({\n",
    "                    'bbox': (x1, y1, x2, y2),\n",
    "                    'confidence': confidence,\n",
    "                    'roi': plate_roi\n",
    "                })\n",
    "            \n",
    "            return plates\n",
    "        except Exception:\n",
    "            return []\n",
    "    \n",
    "    def recognize_text(self, plate_roi):\n",
    "        \"\"\"Recognize text in license plate ROI\"\"\"\n",
    "        if plate_roi is None or plate_roi.size == 0:\n",
    "            return \"\", 0\n",
    "        \n",
    "        # Resize small images for better OCR\n",
    "        h, w = plate_roi.shape[:2]\n",
    "        if h < 32 or w < 100:\n",
    "            scale = max(32/h, 100/w)\n",
    "            plate_roi = cv2.resize(plate_roi, (int(w*scale), int(h*scale)))\n",
    "        \n",
    "        return self.ocr_engine.recognize_text(plate_roi)\n",
    "    \n",
    "    def draw_results(self, frame, plates_info):\n",
    "        \"\"\"Draw detection results on frame\"\"\"\n",
    "        for plate_info in plates_info:\n",
    "            x1, y1, x2, y2 = plate_info['bbox']\n",
    "            confidence = plate_info['confidence']\n",
    "            plate_text = plate_info.get('text', '')\n",
    "            ocr_confidence = plate_info.get('ocr_confidence', 0)\n",
    "            \n",
    "            # Color: green if text detected, yellow if only plate detected\n",
    "            color = (0, 255, 0) if plate_text else (0, 255, 255)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            \n",
    "            # Draw plate confidence\n",
    "            cv2.putText(frame, f'Plate: {confidence:.2f}', \n",
    "                       (x1, y1-30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            \n",
    "            # Draw recognized text\n",
    "            if plate_text:\n",
    "                text_size = cv2.getTextSize(plate_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]\n",
    "                cv2.rectangle(frame, (x1, y1-60), (x1 + text_size[0] + 10, y1-35), (0, 0, 0), -1)\n",
    "                \n",
    "                cv2.putText(frame, plate_text, \n",
    "                           (x1+5, y1-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "                \n",
    "                cv2.putText(frame, f'OCR: {ocr_confidence:.2f}', \n",
    "                           (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def update_fps(self):\n",
    "        \"\"\"Update FPS counter\"\"\"\n",
    "        self.fps_counter += 1\n",
    "        current_time = time.time()\n",
    "        elapsed = current_time - self.fps_start_time\n",
    "        \n",
    "        if elapsed >= 1.0:\n",
    "            self.current_fps = self.fps_counter / elapsed\n",
    "            self.fps_counter = 0\n",
    "            self.fps_start_time = current_time\n",
    "    \n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"Process single frame for license plate detection and OCR\"\"\"\n",
    "        plates = self.detect_license_plates(frame)\n",
    "        \n",
    "        plates_info = []\n",
    "        for plate in plates:\n",
    "            plate_info = {\n",
    "                'bbox': plate['bbox'],\n",
    "                'confidence': plate['confidence']\n",
    "            }\n",
    "            \n",
    "            # Perform OCR if plate ROI is valid\n",
    "            if plate['roi'] is not None and plate['roi'].size > 0:\n",
    "                text, ocr_conf = self.recognize_text(plate['roi'])\n",
    "                if text:\n",
    "                    plate_info['text'] = text\n",
    "                    plate_info['ocr_confidence'] = ocr_conf\n",
    "                    \n",
    "                    # Store successful detection\n",
    "                    if len(text) >= 3:\n",
    "                        detection = {\n",
    "                            'text': text,\n",
    "                            'confidence': plate['confidence'],\n",
    "                            'ocr_confidence': ocr_conf,\n",
    "                            'timestamp': time.time()\n",
    "                        }\n",
    "                        self.recent_plates.append(detection)\n",
    "            \n",
    "            plates_info.append(plate_info)\n",
    "        \n",
    "        self.update_fps()\n",
    "        return plates_info\n",
    "    \n",
    "    def get_ocr_stats(self):\n",
    "        \"\"\"Get OCR statistics\"\"\"\n",
    "        return self.ocr_engine.get_stats()\n",
    "    \n",
    "    def reset_ocr_stats(self):\n",
    "        \"\"\"Reset OCR statistics\"\"\"\n",
    "        self.ocr_engine.reset_stats()\n",
    "\n",
    "def find_trained_models(base_path):\n",
    "    \"\"\"Find trained models in the dataset directory\"\"\"\n",
    "    models = {'plate_model': None}\n",
    "    \n",
    "    search_paths = [\n",
    "        os.path.join(base_path, \"models\"),\n",
    "        os.path.join(base_path, \"dataset\", \"models\"),\n",
    "        os.path.join(base_path, \"datasetocr\", \"models\"),\n",
    "        base_path\n",
    "    ]\n",
    "    \n",
    "    for search_path in search_paths:\n",
    "        if not os.path.exists(search_path):\n",
    "            continue\n",
    "            \n",
    "        if os.path.isdir(search_path):\n",
    "            for file in os.listdir(search_path):\n",
    "                if file.endswith('.pt'):\n",
    "                    full_path = os.path.join(search_path, file)\n",
    "                    if 'plate' in file.lower() or 'red' in file.lower():\n",
    "                        models['plate_model'] = full_path\n",
    "        \n",
    "        # Look for weights/best.pt in subdirectories\n",
    "        try:\n",
    "            for subdir in os.listdir(search_path):\n",
    "                subdir_path = os.path.join(search_path, subdir)\n",
    "                if os.path.isdir(subdir_path):\n",
    "                    weights_dir = os.path.join(subdir_path, \"weights\")\n",
    "                    if os.path.exists(weights_dir):\n",
    "                        best_model = os.path.join(weights_dir, \"best.pt\")\n",
    "                        if os.path.exists(best_model):\n",
    "                            if 'plate' in subdir.lower() or 'red' in subdir.lower():\n",
    "                                models['plate_model'] = best_model\n",
    "        except PermissionError:\n",
    "            continue\n",
    "    \n",
    "    return models\n",
    "\n",
    "def main():\n",
    "    print(\"\\nüöó License Plate Detection & OCR System (EasyOCR Only)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not EASYOCR_AVAILABLE:\n",
    "        print(\"‚ùå EasyOCR is not available!\")\n",
    "        print(\"Install with: pip install easyocr\")\n",
    "        return\n",
    "    \n",
    "    # Find model paths\n",
    "    base_paths = [\n",
    "        \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam\",\n",
    "        \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\",\n",
    "        \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr\"\n",
    "    ]\n",
    "    \n",
    "    models = {'plate_model': None}\n",
    "    \n",
    "    for base_path in base_paths:\n",
    "        if os.path.exists(base_path):\n",
    "            found_models = find_trained_models(base_path)\n",
    "            if found_models['plate_model'] and not models['plate_model']:\n",
    "                models['plate_model'] = found_models['plate_model']\n",
    "    \n",
    "    print(f\"\\nüîç Found models:\")\n",
    "    print(f\"   License Plate Model: {models['plate_model'] or 'Not found'}\")\n",
    "    \n",
    "    # Ask for model path if not found\n",
    "    if not models['plate_model']:\n",
    "        plate_path = input(\"Enter path to license plate detection model (.pt file): \").strip()\n",
    "        if os.path.exists(plate_path):\n",
    "            models['plate_model'] = plate_path\n",
    "        else:\n",
    "            print(\"‚ùå License plate model not found!\")\n",
    "            return\n",
    "    \n",
    "    # Initialize detector\n",
    "    detector = LicensePlateDetector(models['plate_model'])\n",
    "    \n",
    "    # Initialize webcam\n",
    "    print(\"\\nüì∑ Initializing webcam...\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"‚ùå Cannot open webcam!\")\n",
    "        return\n",
    "    \n",
    "    # Set webcam properties\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "    \n",
    "    print(\"‚úÖ Webcam initialized successfully!\")\n",
    "    print(f\"\\nüéØ Controls:\")\n",
    "    print(\"   - Press 'q' to quit\")\n",
    "    print(\"   - Press 's' to save current frame\")\n",
    "    print(\"   - Press 'r' to show recent detections\")\n",
    "    print(\"   - Press 'c' to clear detection history\")\n",
    "    print(\"   - Press 'i' to show OCR statistics\")\n",
    "    print(\"   - Press 'x' to reset OCR statistics\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    save_count = 0\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"‚ùå Failed to read frame from webcam\")\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # Process frame\n",
    "            plates_info = detector.process_frame(frame)\n",
    "            frame = detector.draw_results(frame, plates_info)\n",
    "            \n",
    "            # Draw info overlay\n",
    "            info_y = 30\n",
    "            cv2.putText(frame, f'FPS: {detector.current_fps:.1f}', \n",
    "                       (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.putText(frame, f'Plates: {len(plates_info)}', \n",
    "                       (10, info_y + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.putText(frame, f'Recent: {len(detector.recent_plates)}', \n",
    "                       (10, info_y + 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.putText(frame, 'OCR: EasyOCR', \n",
    "                       (10, info_y + 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "            \n",
    "            # Show OCR stats\n",
    "            stats = detector.get_ocr_stats()\n",
    "            cv2.putText(frame, f'OCR Stats: {stats[\"total_uses\"]} uses, {stats[\"success_rate\"]:.1f}% success', \n",
    "                       (10, info_y + 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)\n",
    "            \n",
    "            # Show latest detection\n",
    "            if detector.recent_plates:\n",
    "                latest = detector.recent_plates[-1]\n",
    "                cv2.putText(frame, f'Latest: {latest[\"text\"]} ({latest[\"ocr_confidence\"]:.2f})', \n",
    "                           (10, info_y + 150), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "            \n",
    "            cv2.imshow('License Plate Detection & OCR - EasyOCR', frame)\n",
    "            \n",
    "            # Handle key press\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('s'):\n",
    "                save_count += 1\n",
    "                filename = f\"detection_frame_{save_count:04d}.jpg\"\n",
    "                cv2.imwrite(filename, frame)\n",
    "                print(f\"üíæ Frame saved: {filename}\")\n",
    "            elif key == ord('r'):\n",
    "                print(\"\\nüìã Recent License Plate Detections:\")\n",
    "                if detector.recent_plates:\n",
    "                    for i, detection in enumerate(reversed(list(detector.recent_plates))):\n",
    "                        timestamp = time.strftime('%H:%M:%S', time.localtime(detection['timestamp']))\n",
    "                        print(f\"   {i+1:2d}. {detection['text']:15s} | \"\n",
    "                              f\"Plate: {detection['confidence']:.2f} | \"\n",
    "                              f\"OCR: {detection['ocr_confidence']:.2f} | \"\n",
    "                              f\"{timestamp}\")\n",
    "                else:\n",
    "                    print(\"   No detections yet\")\n",
    "            elif key == ord('c'):\n",
    "                detector.recent_plates.clear()\n",
    "                print(\"üóëÔ∏è Detection history cleared\")\n",
    "            elif key == ord('i'):\n",
    "                stats = detector.get_ocr_stats()\n",
    "                print(f\"\\nüìä EasyOCR Statistics:\")\n",
    "                print(f\"   Total uses: {stats['total_uses']}\")\n",
    "                print(f\"   Successful detections: {stats['successful_detections']}\")\n",
    "                print(f\"   Success rate: {stats['success_rate']:.1f}%\")\n",
    "                print(f\"   Average confidence: {stats['avg_confidence']:.3f}\")\n",
    "                print(f\"   Average processing time: {stats['avg_time']:.3f}s\")\n",
    "            elif key == ord('x'):\n",
    "                detector.reset_ocr_stats()\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚èπÔ∏è Interrupted by user\")\n",
    "    \n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"‚úÖ Webcam released and windows closed\")\n",
    "        \n",
    "        # Final statistics\n",
    "        stats = detector.get_ocr_stats()\n",
    "        print(f\"\\nüìä Final Session Statistics:\")\n",
    "        print(f\"   Total frames processed: {frame_count}\")\n",
    "        print(f\"   Total detections: {len(detector.recent_plates)}\")\n",
    "        print(f\"   Frames saved: {save_count}\")\n",
    "        print(f\"   EasyOCR uses: {stats['total_uses']}\")\n",
    "        print(f\"   EasyOCR success rate: {stats['success_rate']:.1f}%\")\n",
    "        print(f\"   EasyOCR average confidence: {stats['avg_confidence']:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f3ef0e6-6f3e-43dd-8326-5ff65605a92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhk\\anaconda3\\Lib\\site-packages\\yolov5\\utils\\general.py:34: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources as pkg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ YOLOv5 package available\n",
      "üöó License Plate Detection and OCR System\n",
      "==================================================\n",
      "üîç Searching in: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam\n",
      "üéØ Found OCR model: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam\\datasetocr\\models\\ocr_character_recognition\\weights\\ocr_character_detection_best.pt\n",
      "üéØ Found plate model: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam\\dataset\\models\\red_plate_memory_opt\\weights\\best.pt\n",
      "üîç Searching in: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\n",
      "üéØ Found plate model: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\\models\\red_plate_memory_opt\\weights\\best.pt\n",
      "üîç Searching in: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr\n",
      "üéØ Found OCR model: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr\\models\\ocr_character_recognition\\weights\\ocr_character_detection_best.pt\n",
      "\n",
      "üìÅ Model Status:\n",
      "   License Plate Model: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam\\dataset\\models\\red_plate_memory_opt\\weights\\best.pt\n",
      "   OCR Model: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam\\datasetocr\\models\\ocr_character_recognition\\weights\\ocr_character_detection_best.pt\n",
      "\n",
      "‚úÖ Using models:\n",
      "   Plate: best.pt\n",
      "   OCR: ocr_character_detection_best.pt\n",
      "üîÑ Loading models...\n",
      "‚úÖ License plate model loaded: best.pt\n",
      "üîÑ Loading OCR model from: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr/models/ocr_character_recognition/weights/ocr_character_detection_best.pt\n",
      "‚ö†Ô∏è YOLOv8 loading failed: cannot instantiate 'PosixPath' on your system\n",
      "üîÑ Trying torch.load for: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr/models/ocr_character_recognition/weights/ocr_character_detection_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2025-6-22 Python-3.12.4 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå torch.load failed: cannot instantiate 'PosixPath' on your system\n",
      "‚ùå yolov5.load failed: Invalid CUDA '--device cuda' requested, use '--device cpu' or pass valid CUDA device(s)\n",
      "‚ùå Ultralytics YOLO failed: cannot instantiate 'PosixPath' on your system\n",
      "üîÑ Trying manual YOLOv5 model loading...\n",
      "‚ùå Manual load failed: cannot instantiate 'PosixPath' on your system\n",
      "‚ö†Ô∏è YOLOv5 wrapper loading failed: Failed to load YOLOv5 model with all methods\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  DetectMultiBackend failed: cannot instantiate 'PosixPath' on your system\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Direct YOLOv5 loading failed: cannot instantiate 'PosixPath' on your system\n",
      "‚ùå Direct torch loading failed: cannot instantiate 'PosixPath' on your system\n",
      "‚ùå All OCR model loading methods failed\n",
      "\n",
      "üì∑ Initializing webcam...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "import threading\n",
    "import queue\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Global variable for YOLOv5 availability\n",
    "YOLOV5_AVAILABLE = False\n",
    "\n",
    "def check_and_install_yolov5():\n",
    "    \"\"\"Check and install YOLOv5 if needed\"\"\"\n",
    "    global YOLOV5_AVAILABLE\n",
    "    try:\n",
    "        # Try different ways to import YOLOv5\n",
    "        try:\n",
    "            import yolov5\n",
    "            YOLOV5_AVAILABLE = True\n",
    "            print(\"‚úÖ YOLOv5 package available\")\n",
    "            return True\n",
    "        except ImportError:\n",
    "            pass\n",
    "        \n",
    "        # Try to install yolov5\n",
    "        print(\"üì¶ Installing YOLOv5 package...\")\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'yolov5'])\n",
    "        \n",
    "        try:\n",
    "            import yolov5\n",
    "            YOLOV5_AVAILABLE = True\n",
    "            print(\"‚úÖ YOLOv5 package installed and available\")\n",
    "            return True\n",
    "        except ImportError:\n",
    "            print(\"‚ùå Failed to import yolov5 after installation\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to install YOLOv5: {e}\")\n",
    "        return False\n",
    "\n",
    "# Check YOLOv5 availability at startup\n",
    "check_and_install_yolov5()\n",
    "\n",
    "class YOLOv5Wrapper:\n",
    "    \"\"\"Wrapper class for YOLOv5 model to handle Windows path issues\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path):\n",
    "        self.model_path = str(model_path).replace('\\\\', '/')\n",
    "        self.model = None\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # Try multiple ways to load YOLOv5 model\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Try different methods to load YOLOv5 model\"\"\"\n",
    "        \n",
    "        # Method 1: Direct torch.load\n",
    "        try:\n",
    "            print(f\"üîÑ Trying torch.load for: {self.model_path}\")\n",
    "            checkpoint = torch.load(self.model_path, map_location=self.device)\n",
    "            \n",
    "            # If it's a YOLOv5 model dict\n",
    "            if isinstance(checkpoint, dict) and 'model' in checkpoint:\n",
    "                # Try to reconstruct model from checkpoint\n",
    "                if YOLOV5_AVAILABLE:\n",
    "                    import yolov5\n",
    "                    self.model = yolov5.load(self.model_path, device=self.device)\n",
    "                    print(\"‚úÖ YOLOv5 model loaded via yolov5 package\")\n",
    "                    return\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Model format not recognized for torch.load\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå torch.load failed: {e}\")\n",
    "        \n",
    "        # Method 2: YOLOv5 package\n",
    "        if YOLOV5_AVAILABLE:\n",
    "            try:\n",
    "                import yolov5\n",
    "                self.model = yolov5.load(self.model_path, device=self.device)\n",
    "                print(\"‚úÖ YOLOv5 model loaded via yolov5 package\")\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå yolov5.load failed: {e}\")\n",
    "        \n",
    "        # Method 3: Try to load as Ultralytics format anyway\n",
    "        try:\n",
    "            from ultralytics import YOLO\n",
    "            self.model = YOLO(self.model_path)\n",
    "            print(\"‚úÖ Model loaded as Ultralytics YOLO (might work)\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Ultralytics YOLO failed: {e}\")\n",
    "        \n",
    "        # Method 4: Manual model reconstruction\n",
    "        try:\n",
    "            self._manual_load()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Manual load failed: {e}\")\n",
    "            \n",
    "        if self.model is None:\n",
    "            raise Exception(\"Failed to load YOLOv5 model with all methods\")\n",
    "    \n",
    "    def _manual_load(self):\n",
    "        \"\"\"Manual model loading for YOLOv5\"\"\"\n",
    "        print(\"üîÑ Trying manual YOLOv5 model loading...\")\n",
    "        \n",
    "        # Load checkpoint\n",
    "        checkpoint = torch.load(self.model_path, map_location=self.device)\n",
    "        \n",
    "        # Try to create a basic wrapper\n",
    "        class YOLOv5Model:\n",
    "            def __init__(self, checkpoint, device):\n",
    "                self.checkpoint = checkpoint\n",
    "                self.device = device\n",
    "                self.model = checkpoint.get('model', checkpoint)\n",
    "                if hasattr(self.model, 'to'):\n",
    "                    self.model = self.model.to(device)\n",
    "                    self.model.eval()\n",
    "            \n",
    "            def __call__(self, img):\n",
    "                # Basic inference wrapper\n",
    "                if hasattr(self.model, 'forward'):\n",
    "                    with torch.no_grad():\n",
    "                        results = self.model(img)\n",
    "                    return self._format_results(results)\n",
    "                else:\n",
    "                    raise Exception(\"Model doesn't have forward method\")\n",
    "            \n",
    "            def _format_results(self, results):\n",
    "                # Format results to match expected output\n",
    "                class Results:\n",
    "                    def __init__(self, results):\n",
    "                        self.xyxy = [results] if not isinstance(results, list) else results\n",
    "                \n",
    "                return Results(results)\n",
    "        \n",
    "        self.model = YOLOv5Model(checkpoint, self.device)\n",
    "        print(\"‚úÖ Manual YOLOv5 model loading successful\")\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \"\"\"Run inference\"\"\"\n",
    "        if self.model is None:\n",
    "            raise Exception(\"Model not loaded\")\n",
    "        \n",
    "        return self.model(img)\n",
    "\n",
    "class LicensePlateDetector:\n",
    "    def __init__(self, plate_model_path, ocr_model_path):\n",
    "        \"\"\"\n",
    "        Initialize License Plate Detection and OCR system\n",
    "        \n",
    "        Args:\n",
    "            plate_model_path: Path to trained license plate detection model\n",
    "            ocr_model_path: Path to trained OCR character recognition model\n",
    "        \"\"\"\n",
    "        self.plate_model_path = plate_model_path\n",
    "        self.ocr_model_path = ocr_model_path\n",
    "        \n",
    "        # Load models\n",
    "        print(\"üîÑ Loading models...\")\n",
    "        \n",
    "        # Load plate detection model (usually YOLOv8)\n",
    "        try:\n",
    "            self.plate_model = YOLO(plate_model_path)\n",
    "            print(f\"‚úÖ License plate model loaded: {os.path.basename(plate_model_path)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load plate model: {e}\")\n",
    "            self.plate_model = None\n",
    "        \n",
    "        # Load OCR model with improved error handling\n",
    "        self.ocr_model = None\n",
    "        self.ocr_model_type = None\n",
    "        \n",
    "        self._load_ocr_model()\n",
    "        \n",
    "        # Character mapping for OCR\n",
    "        self.char_map = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', \n",
    "                        'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', \n",
    "                        'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', \n",
    "                        'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "        \n",
    "        # Detection parameters\n",
    "        self.plate_conf_threshold = 0.3\n",
    "        self.ocr_conf_threshold = 0.2\n",
    "        \n",
    "        # Results storage\n",
    "        self.recent_plates = deque(maxlen=10)\n",
    "        self.detection_history = []\n",
    "        \n",
    "        # Performance tracking\n",
    "        self.fps_counter = 0\n",
    "        self.fps_start_time = time.time()\n",
    "        self.current_fps = 0\n",
    "    \n",
    "    def _load_ocr_model(self):\n",
    "        \"\"\"Load OCR model with multiple fallback methods\"\"\"\n",
    "        \n",
    "        # Convert path to handle Windows paths properly\n",
    "        ocr_path = str(self.ocr_model_path).replace('\\\\', '/')\n",
    "        \n",
    "        print(f\"üîÑ Loading OCR model from: {ocr_path}\")\n",
    "        \n",
    "        # Method 1: Try as YOLOv8\n",
    "        try:\n",
    "            self.ocr_model = YOLO(ocr_path)\n",
    "            self.ocr_model_type = \"yolov8\"\n",
    "            print(f\"‚úÖ OCR model loaded as YOLOv8: {os.path.basename(ocr_path)}\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è YOLOv8 loading failed: {e}\")\n",
    "        \n",
    "        # Method 2: Try YOLOv5 wrapper\n",
    "        try:\n",
    "            self.ocr_model = YOLOv5Wrapper(ocr_path)\n",
    "            self.ocr_model_type = \"yolov5_wrapper\"\n",
    "            print(f\"‚úÖ OCR model loaded as YOLOv5 wrapper: {os.path.basename(ocr_path)}\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è YOLOv5 wrapper loading failed: {e}\")\n",
    "        \n",
    "        # Method 3: Direct YOLOv5 if available\n",
    "        if YOLOV5_AVAILABLE:\n",
    "            try:\n",
    "                import yolov5\n",
    "                self.ocr_model = yolov5.load(ocr_path)\n",
    "                self.ocr_model_type = \"yolov5\"\n",
    "                print(f\"‚úÖ OCR model loaded as YOLOv5: {os.path.basename(ocr_path)}\")\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Direct YOLOv5 loading failed: {e}\")\n",
    "        \n",
    "        # Method 4: Try loading with torch directly\n",
    "        try:\n",
    "            checkpoint = torch.load(ocr_path, map_location='cpu')\n",
    "            print(\"‚úÖ Model checkpoint loaded successfully\")\n",
    "            print(\"‚ö†Ô∏è Manual inference implementation needed\")\n",
    "            # You would need to implement manual inference here\n",
    "            # For now, we'll skip this\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Direct torch loading failed: {e}\")\n",
    "        \n",
    "        print(\"‚ùå All OCR model loading methods failed\")\n",
    "    \n",
    "    def detect_license_plates(self, frame):\n",
    "        \"\"\"Detect license plates in frame\"\"\"\n",
    "        if self.plate_model is None:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            results = self.plate_model(frame, conf=self.plate_conf_threshold, verbose=False)\n",
    "            plates = []\n",
    "            \n",
    "            for result in results:\n",
    "                if result.boxes is not None:\n",
    "                    for box in result.boxes:\n",
    "                        # Get bounding box coordinates\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                        confidence = float(box.conf[0])\n",
    "                        \n",
    "                        # Extract plate region\n",
    "                        plate_roi = frame[y1:y2, x1:x2]\n",
    "                        \n",
    "                        plates.append({\n",
    "                            'bbox': (x1, y1, x2, y2),\n",
    "                            'confidence': confidence,\n",
    "                            'roi': plate_roi\n",
    "                        })\n",
    "            \n",
    "            return plates\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Plate detection error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def recognize_characters(self, plate_roi):\n",
    "        \"\"\"Recognize characters in license plate ROI\"\"\"\n",
    "        if self.ocr_model is None or plate_roi is None or plate_roi.size == 0:\n",
    "            return \"\", 0, []\n",
    "        \n",
    "        try:\n",
    "            # Preprocess plate ROI\n",
    "            if len(plate_roi.shape) == 3:\n",
    "                plate_gray = cv2.cvtColor(plate_roi, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                plate_gray = plate_roi\n",
    "            \n",
    "            # Enhance contrast\n",
    "            plate_enhanced = cv2.equalizeHist(plate_gray)\n",
    "            \n",
    "            # Convert back to BGR for YOLO\n",
    "            plate_bgr = cv2.cvtColor(plate_enhanced, cv2.COLOR_GRAY2BGR)\n",
    "            \n",
    "            # Resize if too small\n",
    "            h, w = plate_bgr.shape[:2]\n",
    "            if h < 32 or w < 100:\n",
    "                scale = max(32/h, 100/w)\n",
    "                plate_bgr = cv2.resize(plate_bgr, (int(w*scale), int(h*scale)))\n",
    "            \n",
    "            characters = []\n",
    "            \n",
    "            # Handle different model types\n",
    "            if self.ocr_model_type == \"yolov8\":\n",
    "                characters = self._recognize_yolov8(plate_bgr)\n",
    "            elif self.ocr_model_type == \"yolov5\":\n",
    "                characters = self._recognize_yolov5(plate_bgr)\n",
    "            elif self.ocr_model_type == \"yolov5_wrapper\":\n",
    "                characters = self._recognize_yolov5_wrapper(plate_bgr)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Unknown model type: {self.ocr_model_type}\")\n",
    "                return \"\", 0, []\n",
    "            \n",
    "            # Sort and build text\n",
    "            characters.sort(key=lambda x: x['center_x'])\n",
    "            plate_text = ''.join([char['char'] for char in characters])\n",
    "            avg_confidence = np.mean([char['confidence'] for char in characters]) if characters else 0\n",
    "            \n",
    "            return plate_text, avg_confidence, characters\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå OCR error: {e}\")\n",
    "            return \"\", 0, []\n",
    "    \n",
    "    def _recognize_yolov8(self, plate_bgr):\n",
    "        \"\"\"YOLOv8 recognition\"\"\"\n",
    "        results = self.ocr_model(plate_bgr, conf=self.ocr_conf_threshold, verbose=False)\n",
    "        characters = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result.boxes is not None:\n",
    "                for box in result.boxes:\n",
    "                    class_id = int(box.cls[0])\n",
    "                    confidence = float(box.conf[0])\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    \n",
    "                    if class_id < len(self.char_map):\n",
    "                        char = self.char_map[class_id]\n",
    "                        characters.append({\n",
    "                            'char': char,\n",
    "                            'confidence': confidence,\n",
    "                            'bbox': (x1, y1, x2, y2),\n",
    "                            'center_x': (x1 + x2) / 2\n",
    "                        })\n",
    "        \n",
    "        return characters\n",
    "    \n",
    "    def _recognize_yolov5(self, plate_bgr):\n",
    "        \"\"\"YOLOv5 recognition\"\"\"\n",
    "        results = self.ocr_model(plate_bgr)\n",
    "        characters = []\n",
    "        \n",
    "        # Handle different YOLOv5 result formats\n",
    "        try:\n",
    "            if hasattr(results, 'pandas'):\n",
    "                df = results.pandas().xyxy[0]\n",
    "                for _, row in df.iterrows():\n",
    "                    if row['confidence'] >= self.ocr_conf_threshold:\n",
    "                        class_id = int(row['class'])\n",
    "                        confidence = float(row['confidence'])\n",
    "                        x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n",
    "                        \n",
    "                        if class_id < len(self.char_map):\n",
    "                            char = self.char_map[class_id]\n",
    "                            characters.append({\n",
    "                                'char': char,\n",
    "                                'confidence': confidence,\n",
    "                                'bbox': (x1, y1, x2, y2),\n",
    "                                'center_x': (x1 + x2) / 2\n",
    "                            })\n",
    "            else:\n",
    "                # Tensor format\n",
    "                for *box, conf, cls in results.xyxy[0].cpu().numpy():\n",
    "                    if conf >= self.ocr_conf_threshold:\n",
    "                        class_id = int(cls)\n",
    "                        confidence = float(conf)\n",
    "                        x1, y1, x2, y2 = map(int, box)\n",
    "                        \n",
    "                        if class_id < len(self.char_map):\n",
    "                            char = self.char_map[class_id]\n",
    "                            characters.append({\n",
    "                                'char': char,\n",
    "                                'confidence': confidence,\n",
    "                                'bbox': (x1, y1, x2, y2),\n",
    "                                'center_x': (x1 + x2) / 2\n",
    "                            })\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è YOLOv5 result parsing error: {e}\")\n",
    "        \n",
    "        return characters\n",
    "    \n",
    "    def _recognize_yolov5_wrapper(self, plate_bgr):\n",
    "        \"\"\"YOLOv5 wrapper recognition\"\"\"\n",
    "        try:\n",
    "            results = self.ocr_model(plate_bgr)\n",
    "            # This would need custom implementation based on the wrapper\n",
    "            # For now, return empty\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è YOLOv5 wrapper error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def draw_results(self, frame, plates_info):\n",
    "        \"\"\"Draw detection results on frame\"\"\"\n",
    "        for plate_info in plates_info:\n",
    "            x1, y1, x2, y2 = plate_info['bbox']\n",
    "            confidence = plate_info['confidence']\n",
    "            plate_text = plate_info.get('text', '')\n",
    "            ocr_confidence = plate_info.get('ocr_confidence', 0)\n",
    "            \n",
    "            # Draw license plate bounding box\n",
    "            color = (0, 255, 0) if plate_text else (0, 255, 255)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            \n",
    "            # Draw plate detection confidence\n",
    "            cv2.putText(frame, f'Plate: {confidence:.2f}', \n",
    "                       (x1, y1-30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            \n",
    "            # Draw recognized text\n",
    "            if plate_text:\n",
    "                text_size = cv2.getTextSize(plate_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]\n",
    "                cv2.rectangle(frame, (x1, y1-60), (x1 + text_size[0] + 10, y1-35), (0, 0, 0), -1)\n",
    "                \n",
    "                cv2.putText(frame, plate_text, \n",
    "                           (x1+5, y1-40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "                \n",
    "                cv2.putText(frame, f'OCR: {ocr_confidence:.2f}', \n",
    "                           (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # Draw model info\n",
    "        model_info = f\"Plate: YOLOv8 | OCR: {self.ocr_model_type or 'None'}\"\n",
    "        cv2.putText(frame, model_info, (10, frame.shape[0] - 10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def update_fps(self):\n",
    "        \"\"\"Update FPS counter\"\"\"\n",
    "        self.fps_counter += 1\n",
    "        current_time = time.time()\n",
    "        elapsed = current_time - self.fps_start_time\n",
    "        \n",
    "        if elapsed >= 1.0:\n",
    "            self.current_fps = self.fps_counter / elapsed\n",
    "            self.fps_counter = 0\n",
    "            self.fps_start_time = current_time\n",
    "    \n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"Process single frame for license plate detection and OCR\"\"\"\n",
    "        plates = self.detect_license_plates(frame)\n",
    "        \n",
    "        plates_info = []\n",
    "        for plate in plates:\n",
    "            plate_info = {\n",
    "                'bbox': plate['bbox'],\n",
    "                'confidence': plate['confidence']\n",
    "            }\n",
    "            \n",
    "            if plate['roi'] is not None and plate['roi'].size > 0:\n",
    "                ocr_result = self.recognize_characters(plate['roi'])\n",
    "                if len(ocr_result) == 3:\n",
    "                    text, ocr_conf, characters = ocr_result\n",
    "                    plate_info['text'] = text\n",
    "                    plate_info['ocr_confidence'] = ocr_conf\n",
    "                    plate_info['characters'] = characters\n",
    "                    \n",
    "                    if text and len(text) >= 3:\n",
    "                        detection = {\n",
    "                            'text': text,\n",
    "                            'confidence': plate['confidence'],\n",
    "                            'ocr_confidence': ocr_conf,\n",
    "                            'timestamp': time.time()\n",
    "                        }\n",
    "                        self.recent_plates.append(detection)\n",
    "            \n",
    "            plates_info.append(plate_info)\n",
    "        \n",
    "        self.update_fps()\n",
    "        return plates_info\n",
    "\n",
    "def find_trained_models(base_path):\n",
    "    \"\"\"Find trained models in the dataset directory\"\"\"\n",
    "    models = {\n",
    "        'plate_model': None,\n",
    "        'ocr_model': None\n",
    "    }\n",
    "    \n",
    "    # Specific search for OCR character detection model\n",
    "    ocr_model_paths = [\n",
    "        os.path.join(base_path, \"datasetocr\", \"models\", \"ocr_character_recognition\", \"weights\", \"ocr_character_detection_best.pt\"),\n",
    "        os.path.join(base_path, \"models\", \"ocr_character_recognition\", \"weights\", \"ocr_character_detection_best.pt\"),\n",
    "        os.path.join(base_path, \"ocr_character_recognition\", \"weights\", \"ocr_character_detection_best.pt\"),\n",
    "        os.path.join(base_path, \"datasetocr\", \"models\", \"ocr_character_recognition\", \"weights\", \"best.pt\"),\n",
    "        os.path.join(base_path, \"models\", \"ocr_character_recognition\", \"weights\", \"best.pt\"),\n",
    "    ]\n",
    "    \n",
    "    for ocr_path in ocr_model_paths:\n",
    "        if os.path.exists(ocr_path):\n",
    "            models['ocr_model'] = ocr_path\n",
    "            print(f\"üéØ Found OCR model: {ocr_path}\")\n",
    "            break\n",
    "    \n",
    "    # Look for license plate model\n",
    "    search_paths = [\n",
    "        os.path.join(base_path, \"models\"),\n",
    "        os.path.join(base_path, \"dataset\", \"models\"),\n",
    "        os.path.join(base_path, \"datasetocr\", \"models\"),\n",
    "        base_path\n",
    "    ]\n",
    "    \n",
    "    for search_path in search_paths:\n",
    "        if not os.path.exists(search_path):\n",
    "            continue\n",
    "            \n",
    "        for subdir in os.listdir(search_path):\n",
    "            subdir_path = os.path.join(search_path, subdir)\n",
    "            if os.path.isdir(subdir_path):\n",
    "                weights_dir = os.path.join(subdir_path, \"weights\")\n",
    "                if os.path.exists(weights_dir):\n",
    "                    best_model = os.path.join(weights_dir, \"best.pt\")\n",
    "                    if os.path.exists(best_model):\n",
    "                        if 'ocr' not in subdir.lower() and 'character' not in subdir.lower():\n",
    "                            if 'plate' in subdir.lower() or 'red' in subdir.lower() or not models['plate_model']:\n",
    "                                models['plate_model'] = best_model\n",
    "                                print(f\"üéØ Found plate model: {best_model}\")\n",
    "    \n",
    "    return models\n",
    "\n",
    "def main():\n",
    "    print(\"üöó License Plate Detection and OCR System\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Base paths\n",
    "    base_paths = [\n",
    "        \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam\",\n",
    "        \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\",\n",
    "        \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/datasetocr\",\n",
    "    ]\n",
    "    \n",
    "    # Find trained models\n",
    "    models = {'plate_model': None, 'ocr_model': None}\n",
    "    \n",
    "    for base_path in base_paths:\n",
    "        if os.path.exists(base_path):\n",
    "            print(f\"üîç Searching in: {base_path}\")\n",
    "            found_models = find_trained_models(base_path)\n",
    "            if found_models['plate_model'] and not models['plate_model']:\n",
    "                models['plate_model'] = found_models['plate_model']\n",
    "            if found_models['ocr_model'] and not models['ocr_model']:\n",
    "                models['ocr_model'] = found_models['ocr_model']\n",
    "    \n",
    "    print(\"\\nüìÅ Model Status:\")\n",
    "    print(f\"   License Plate Model: {models['plate_model'] or '‚ùå Not found'}\")\n",
    "    print(f\"   OCR Model: {models['ocr_model'] or '‚ùå Not found'}\")\n",
    "    \n",
    "    if not models['plate_model'] or not models['ocr_model']:\n",
    "        print(\"‚ùå Required models not found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n‚úÖ Using models:\")\n",
    "    print(f\"   Plate: {os.path.basename(models['plate_model'])}\")\n",
    "    print(f\"   OCR: {os.path.basename(models['ocr_model'])}\")\n",
    "    \n",
    "    # Initialize detector\n",
    "    detector = LicensePlateDetector(models['plate_model'], models['ocr_model'])\n",
    "    \n",
    "    # Initialize webcam\n",
    "    print(\"\\nüì∑ Initializing webcam...\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"‚ùå Cannot open webcam!\")\n",
    "        return\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "    \n",
    "    print(\"‚úÖ Webcam initialized successfully!\")\n",
    "    print(f\"üîß Using OCR model type: {detector.ocr_model_type}\")\n",
    "    print(\"\\nüéØ Controls:\")\n",
    "    print(\"   - Press 'q' to quit\")\n",
    "    print(\"   - Press 's' to save current frame\")\n",
    "    print(\"   - Press 'r' to show recent detections\")\n",
    "    print(\"   - Press 'c' to clear detection history\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    save_count = 0\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"‚ùå Failed to read frame from webcam\")\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # Process frame (only plate detection if OCR failed)\n",
    "            if detector.ocr_model is not None:\n",
    "                plates_info = detector.process_frame(frame)\n",
    "            else:\n",
    "                # Only do plate detection\n",
    "                plates = detector.detect_license_plates(frame)\n",
    "                plates_info = [{'bbox': p['bbox'], 'confidence': p['confidence']} for p in plates]\n",
    "            \n",
    "            # Draw results\n",
    "            frame = detector.draw_results(frame, plates_info)\n",
    "            \n",
    "            # Draw info panel\n",
    "            info_y = 30\n",
    "            cv2.putText(frame, f'FPS: {detector.current_fps:.1f}', \n",
    "                       (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.putText(frame, f'Plates Detected: {len(plates_info)}', \n",
    "                       (10, info_y + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            if detector.ocr_model is None:\n",
    "                cv2.putText(frame, 'OCR: Not Available', \n",
    "                           (10, info_y + 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            \n",
    "            cv2.imshow('License Plate Detection & OCR', frame)\n",
    "            \n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('s'):\n",
    "                save_count += 1\n",
    "                filename = f\"detection_frame_{save_count:04d}.jpg\"\n",
    "                cv2.imwrite(filename, frame)\n",
    "                print(f\"üíæ Frame saved: {filename}\")\n",
    "            elif key == ord('r'):\n",
    "                print(\"\\nüìã Recent License Plate Detections:\")\n",
    "                if detector.recent_plates:\n",
    "                    for i, detection in enumerate(reversed(list(detector.recent_plates))):\n",
    "                        timestamp = time.strftime('%H:%M:%S', time.localtime(detection['timestamp']))\n",
    "                        print(f\"   {i+1:2d}. {detection['text']:12s} | \"\n",
    "                              f\"Plate: {detection['confidence']:.2f} | \"\n",
    "                              f\"OCR: {detection['ocr_confidence']:.2f} | \"\n",
    "                              f\"{timestamp}\")\n",
    "                else:\n",
    "                    print(\"   No detections yet\")\n",
    "            elif key == ord('c'):\n",
    "                detector.recent_plates.clear()\n",
    "                detector.detection_history.clear()\n",
    "                print(\"üóëÔ∏è  Detection history cleared\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚èπÔ∏è  Interrupted by user\")\n",
    "    \n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"‚úÖ Webcam released and windows closed\")\n",
    "        \n",
    "        print(f\"\\nüìä Session Statistics:\")\n",
    "        print(f\"   Total frames processed: {frame_count}\")\n",
    "        print(f\"   Total detections: {len(detector.recent_plates)}\")\n",
    "        print(f\"   Frames saved: {save_count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06e97f7-06bc-4030-9aa6-034b0966b778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
