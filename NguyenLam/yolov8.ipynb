{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "838fc189-1f4f-4dae-b47e-96ccb56702cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose training mode:\n",
      "1. Memory Optimized (Recommended)\n",
      "2. CPU Training\n",
      "3. Ultra Minimal\n",
      "4. Download Pretrained Models Only\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter choice (1/2/3/4) [default: 1]:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¥ Memory-Optimized YOLOv8 Red License Plate Training\n",
      "============================================================\n",
      "üñ•Ô∏è  GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "üíæ Total GPU Memory: 4.0 GB\n",
      "ü§ñ Using YOLOv8n (Nano) for memory efficiency...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.25M/6.25M [00:00<00:00, 11.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Memory-Optimized Configuration:\n",
      "   Image size: 416\n",
      "   Batch size: 2\n",
      "   Workers: 2\n",
      "   AMP enabled: True\n",
      "   Models will be saved to: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\\models\n",
      "============================================================\n",
      "üöÄ Starting memory-optimized training...\n",
      "Ultralytics 8.3.156  Python-3.12.4 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=2, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/minhk/Downloads/code thu/AI/NguyenLam/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=0.9, freeze=None, half=False, hsv_h=0.01, hsv_s=0.5, hsv_v=0.3, imgsz=416, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.005, lrf=0.1, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=red_plate_memory_opt, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/minhk/Downloads/code thu/AI/NguyenLam/dataset\\models, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\models\\red_plate_memory_opt, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.3, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.05, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 8.75MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 1.50.6 MB/s, size: 18.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\minhk\\Downloads\\code thu√™\\AI\\NguyenLam\\dataset\\train\\labels... 6351 images, 5 backgrounds, 0 c\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\train\\labels.cache\n",
      "WARNING 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 2.61.0 MB/s, size: 21.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\minhk\\Downloads\\code thu√™\\AI\\NguyenLam\\dataset\\valid\\labels... 2048 images, 3 backgrounds, 0 cor\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\valid\\labels.cache\n",
      "Plotting labels to C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\models\\red_plate_memory_opt\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.005' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\models\\red_plate_memory_opt\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100     0.209G      1.446      1.312      1.228          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:42<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.574       0.53      0.543      0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100     0.209G      1.517      1.128      1.329          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.611      0.612        0.6      0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100     0.209G      1.503       1.09      1.335          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.872      0.705        0.8      0.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100     0.209G      1.503      1.034      1.381          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.892      0.677      0.797      0.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100     0.209G      1.481     0.9787      1.357          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.804       0.68      0.791      0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100     0.209G      1.449     0.9392      1.338          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.86      0.756      0.841      0.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100     0.209G      1.442     0.9245      1.345          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.847      0.762      0.838      0.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100     0.209G      1.411     0.8508      1.315          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.895       0.79      0.874      0.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100     0.209G      1.398     0.8317      1.314          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195        0.9       0.81      0.888      0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100     0.209G      1.408     0.8198      1.315          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.904      0.828      0.889       0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100     0.209G      1.377     0.8066      1.301          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:42<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.91      0.823      0.895      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100     0.209G       1.38     0.7746      1.302          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:43<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.915      0.845      0.902      0.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100     0.209G      1.355     0.7704      1.285          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:42<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.922      0.836      0.904      0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100     0.209G      1.362     0.7542      1.279          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:42<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.902      0.841      0.902      0.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100     0.209G      1.359     0.7497      1.287          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.931      0.858      0.914       0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100     0.209G      1.349     0.7304      1.273          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:44<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.943      0.873      0.921      0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100     0.209G       1.34     0.7054      1.268          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.94      0.869      0.921      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100     0.209G      1.336     0.7175      1.261          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.946      0.867      0.918      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100     0.209G      1.334     0.7307      1.258          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.938      0.872      0.921      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100     0.209G       1.32     0.6963      1.248          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.964      0.886      0.931      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100     0.209G      1.324     0.7017      1.256          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:44<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.963      0.872      0.927       0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100     0.209G      1.313     0.6964      1.246          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.953      0.889       0.93      0.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100     0.209G      1.306     0.6929      1.246          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.959      0.885      0.933      0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100     0.209G      1.314     0.6801      1.245          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.957      0.887      0.936      0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100     0.209G      1.311     0.6633      1.241          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.963       0.88      0.933      0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100     0.209G      1.302      0.671      1.238          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:34<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.96      0.888      0.939      0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100     0.209G      1.294     0.6445      1.232          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.965      0.889      0.938      0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100     0.209G      1.279     0.6451      1.223          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.964      0.886      0.934      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100     0.209G      1.286     0.6319      1.228          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:33<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.976      0.895      0.943      0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100     0.209G      1.272     0.6189      1.221          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.967      0.902      0.942      0.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100     0.209G      1.277     0.6199      1.219          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979        0.9      0.946      0.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100     0.209G       1.26     0.6157      1.216          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:33<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.965      0.905      0.943      0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100     0.209G      1.263      0.618      1.211          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:32<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.963      0.908      0.947      0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100     0.209G       1.25     0.6112      1.205          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:34<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.978      0.899      0.948      0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100     0.209G      1.261     0.6057      1.211          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.973      0.898      0.946      0.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100     0.209G      1.244     0.5925      1.203          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.971      0.897      0.944      0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100     0.209G      1.245     0.5922      1.204          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.977      0.901      0.947      0.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100     0.209G      1.244     0.5877      1.197          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.968      0.901      0.943       0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100     0.209G      1.236     0.5874      1.201          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.974      0.904      0.946      0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100     0.209G      1.221      0.577      1.188          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:45<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979      0.903      0.949      0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100     0.209G       1.22     0.5714      1.186          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.98      0.904      0.946        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100     0.209G      1.226     0.5732      1.192          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:40<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.97       0.91      0.952      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100     0.209G      1.229     0.5722      1.194          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.977      0.899      0.949        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100     0.209G      1.215     0.5693      1.188          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.967      0.907       0.95      0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100     0.209G      1.218     0.5684      1.191          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.98      0.904       0.95      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100     0.209G       1.21     0.5672      1.186          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:41<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.974      0.901      0.949      0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100     0.209G      1.217     0.5666      1.187          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:41<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.98      0.902      0.951      0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100     0.209G      1.202     0.5528       1.18          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.975      0.899      0.948      0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100     0.209G      1.202     0.5527      1.179          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.973      0.907      0.948      0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100     0.209G      1.194     0.5517       1.17          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:34<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.972      0.905      0.951      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100     0.209G      1.201     0.5452      1.177          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.978      0.908      0.952      0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100     0.209G      1.188     0.5383      1.167          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:32<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.969      0.899      0.946      0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100     0.209G      1.189     0.5406      1.171          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:31<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.986      0.898      0.952       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100     0.209G      1.189       0.54      1.168          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:31<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.975      0.909       0.95       0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100     0.209G      1.185     0.5339      1.163          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:30<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.97      0.912      0.952      0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100     0.209G      1.175      0.528      1.167          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:30<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.977      0.913      0.953      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100     0.209G      1.173     0.5263       1.16          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:31<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.974      0.902      0.949      0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100     0.209G       1.17     0.5284      1.157          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:31<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979      0.908      0.951      0.631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100     0.209G      1.162     0.5252      1.155          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:33<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.969      0.907      0.948      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100     0.209G      1.168     0.5221      1.159          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:31<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.968      0.909      0.951      0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100     0.209G      1.154      0.518       1.15          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:32<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.957      0.895      0.942      0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100     0.209G      1.161     0.5147      1.154          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:33<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.978      0.907       0.95      0.628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100     0.209G      1.157     0.5131       1.15          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:38<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.96      0.907      0.947      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100     0.209G      1.148     0.5112      1.142          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:32<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.968      0.888      0.947      0.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100     0.209G      1.149     0.5063      1.144          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:30<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.975      0.908      0.954      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100     0.209G      1.154     0.5045      1.142          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:30<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.901      0.954      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100     0.209G      1.144     0.5009      1.146          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:30<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.977      0.902       0.95      0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100     0.209G      1.143     0.5013      1.143          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:31<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.977      0.901      0.951      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100     0.209G       1.14     0.4997      1.136          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:30<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979      0.904       0.95      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100     0.209G      1.141      0.497      1.139          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:34<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979      0.903      0.951      0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100     0.209G      1.133     0.4908      1.136          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.901      0.952      0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100     0.209G      1.134      0.489      1.138          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.978      0.897       0.95      0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100     0.209G      1.135     0.4881      1.136          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195       0.98      0.895      0.946      0.628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100     0.209G      1.125     0.4865      1.135          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.902       0.95      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100     0.209G      1.128     0.4834      1.136          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:32<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.982      0.902      0.949      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100     0.209G      1.115     0.4832      1.125          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.975      0.905      0.947      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100     0.209G       1.11      0.476      1.125          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.978      0.909       0.95      0.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100     0.209G      1.107     0.4768       1.12          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979        0.9       0.95      0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100     0.209G       1.11     0.4749      1.124          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.981      0.903      0.952      0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100     0.209G      1.106     0.4689      1.114          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.977       0.91      0.954      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100     0.209G      1.092     0.4671      1.116          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:34<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.977      0.911      0.952      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100     0.209G      1.091     0.4688      1.113          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:39<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.985      0.896      0.946      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100     0.209G      1.093     0.4674      1.112          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.979      0.909      0.946      0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100     0.209G      1.078     0.4586      1.109          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.977      0.906      0.947      0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100     0.209G      1.084     0.4608      1.109          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.974      0.912      0.952      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100     0.209G       1.08     0.4594      1.107          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.976      0.906      0.949      0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100     0.209G       1.07     0.4568      1.104          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.982      0.905      0.947      0.639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100     0.209G      1.068     0.4522      1.101          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:32<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.982      0.901       0.94      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100     0.209G      1.069     0.4523        1.1          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:33<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.986      0.894      0.938      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100     0.209G      1.061     0.4483        1.1          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.982      0.888      0.934      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100     0.209G      1.058     0.4479      1.097          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.989      0.883      0.927      0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100     0.209G      1.052     0.4467      1.097          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:36<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.988      0.886       0.93       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100     0.209G      1.052     0.4431      1.093          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:32<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.986      0.892      0.935      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100     0.209G      1.044      0.441      1.093          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:33<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.893      0.934      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100     0.209G      1.041     0.4421      1.088          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:35<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.889      0.933      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100     0.209G      1.035     0.4395      1.088          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3176/3176 [04:33<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.887      0.932      0.626\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 30 epochs. Best results observed at epoch 66, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=30) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "96 epochs completed in 8.145 hours.\n",
      "Optimizer stripped from C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\models\\red_plate_memory_opt\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\models\\red_plate_memory_opt\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating C:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\models\\red_plate_memory_opt\\weights\\best.pt...\n",
      "Ultralytics 8.3.156  Python-3.12.4 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512/512 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.983      0.901      0.954      0.647\n",
      "Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\models\\red_plate_memory_opt\u001b[0m\n",
      "üéâ Training completed successfully!\n",
      "üíæ Best model saved at: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\\models\\red_plate_memory_opt/weights/best.pt\n",
      "\n",
      "üîç Running validation...\n",
      "Ultralytics 8.3.156  Python-3.12.4 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 34.813.6 MB/s, size: 20.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\minhk\\Downloads\\code thu√™\\AI\\NguyenLam\\dataset\\valid\\labels.cache... 2048 images, 3 backgrounds,\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1024/1024 [0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2048       2195      0.984      0.901      0.955      0.647\n",
      "Speed: 0.2ms preprocess, 5.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\minhk\\Downloads\\code thu\\AI\\NguyenLam\\dataset\\models\\red_plate_memory_opt\u001b[0m\n",
      "üìä Validation Results:\n",
      "   mAP50: 0.9548\n",
      "   mAP50-95: 0.6471\n",
      "   Precision: 0.9836\n",
      "   Recall: 0.9007\n",
      "\n",
      "‚úÖ Training successful! Model saved at: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\\models\\red_plate_memory_opt\n",
      "üìÅ Best weights: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\\models\\red_plate_memory_opt/weights/best.pt\n",
      "üìÅ Last weights: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\\models\\red_plate_memory_opt/weights/last.pt\n",
      "üìÅ Training results: C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\\models\\red_plate_memory_opt\n",
      "\n",
      "üìÇ Directory structure:\n",
      "   C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset/\n",
      "   ‚îú‚îÄ‚îÄ models/\n",
      "   ‚îÇ   ‚îî‚îÄ‚îÄ red_plate_memory_opt/\n",
      "   ‚îÇ       ‚îú‚îÄ‚îÄ weights/\n",
      "   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ best.pt\n",
      "   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ last.pt\n",
      "   ‚îÇ       ‚îú‚îÄ‚îÄ results.png\n",
      "   ‚îÇ       ‚îî‚îÄ‚îÄ confusion_matrix.png\n",
      "   ‚îî‚îÄ‚îÄ data.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import gc\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear GPU memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def optimize_gpu_memory():\n",
    "    \"\"\"Optimize GPU memory settings\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        # Set memory allocation strategy\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "        \n",
    "        # Clear cache\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Get GPU info\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"üñ•Ô∏è  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"üíæ Total GPU Memory: {gpu_memory:.1f} GB\")\n",
    "        \n",
    "        # Calculate optimal batch size for different GPU memory sizes\n",
    "        if gpu_memory <= 4:\n",
    "            recommended_batch = 2\n",
    "            recommended_workers = 2\n",
    "        elif gpu_memory <= 6:\n",
    "            recommended_batch = 4\n",
    "            recommended_workers = 4\n",
    "        elif gpu_memory <= 8:\n",
    "            recommended_batch = 8\n",
    "            recommended_workers = 6\n",
    "        else:\n",
    "            recommended_batch = 16\n",
    "            recommended_workers = 8\n",
    "            \n",
    "        return recommended_batch, recommended_workers\n",
    "    else:\n",
    "        return 4, 2  # CPU fallback\n",
    "\n",
    "def train_memory_optimized():\n",
    "    print(\"üî¥ Memory-Optimized YOLOv8 Red License Plate Training\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Clear memory first\n",
    "    clear_memory()\n",
    "    \n",
    "    # Optimize memory settings\n",
    "    batch_size, workers = optimize_gpu_memory()\n",
    "    \n",
    "    # Dataset path\n",
    "    dataset_path = \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\"\n",
    "    \n",
    "    # Create models directory in dataset path\n",
    "    models_dir = os.path.join(dataset_path, \"models\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    # Use smaller model for limited GPU memory\n",
    "    print(\"ü§ñ Using YOLOv8n (Nano) for memory efficiency...\")\n",
    "    model = YOLO('yolov8n.pt')\n",
    "    \n",
    "    # Memory-optimized training configuration\n",
    "    train_config = {\n",
    "        'data': f'{dataset_path}/data.yaml',\n",
    "        'epochs': 100,\n",
    "        'imgsz': 416,\n",
    "        'batch': batch_size,\n",
    "        'name': 'red_plate_memory_opt',\n",
    "        'patience': 30,\n",
    "        'save': True,\n",
    "        'plots': True,\n",
    "        'device': 0 if torch.cuda.is_available() else 'cpu',\n",
    "        'workers': workers,\n",
    "        'project': models_dir,  # Changed to save in dataset/models\n",
    "        'exist_ok': True,\n",
    "        \n",
    "        # Memory optimization\n",
    "        'amp': True,\n",
    "        'fraction': 0.9,\n",
    "        'cache': False,\n",
    "        'rect': True,\n",
    "        'resume': False,\n",
    "        'single_cls': False,\n",
    "        \n",
    "        # Learning rate parameters\n",
    "        'lr0': 0.005,\n",
    "        'lrf': 0.1,\n",
    "        'momentum': 0.937,\n",
    "        'weight_decay': 0.0005,\n",
    "        'warmup_epochs': 2,\n",
    "        'warmup_momentum': 0.8,\n",
    "        'warmup_bias_lr': 0.1,\n",
    "        \n",
    "        # Loss weights\n",
    "        'box': 7.5,\n",
    "        'cls': 0.5,\n",
    "        'dfl': 1.5,\n",
    "        \n",
    "        # Data augmentation parameters\n",
    "        'hsv_h': 0.01,\n",
    "        'hsv_s': 0.5,\n",
    "        'hsv_v': 0.3,\n",
    "        'degrees': 0.0,\n",
    "        'translate': 0.05,\n",
    "        'scale': 0.3,\n",
    "        'shear': 0.0,\n",
    "        'perspective': 0.0,\n",
    "        'flipud': 0.0,\n",
    "        'fliplr': 0.5,\n",
    "        'mosaic': 0.5,\n",
    "        'mixup': 0.0,\n",
    "        'copy_paste': 0.0\n",
    "    }\n",
    "    \n",
    "    print(\"üìã Memory-Optimized Configuration:\")\n",
    "    print(f\"   Image size: {train_config['imgsz']}\")\n",
    "    print(f\"   Batch size: {train_config['batch']}\")\n",
    "    print(f\"   Workers: {train_config['workers']}\")\n",
    "    print(f\"   AMP enabled: {train_config['amp']}\")\n",
    "    print(f\"   Models will be saved to: {models_dir}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Clear memory before training\n",
    "        clear_memory()\n",
    "        \n",
    "        # Start training\n",
    "        print(\"üöÄ Starting memory-optimized training...\")\n",
    "        results = model.train(**train_config)\n",
    "        \n",
    "        print(\"üéâ Training completed successfully!\")\n",
    "        \n",
    "        # Get the actual save directory\n",
    "        save_dir = os.path.join(models_dir, 'red_plate_memory_opt')\n",
    "        print(f\"üíæ Best model saved at: {save_dir}/weights/best.pt\")\n",
    "        \n",
    "        # Clear memory after training\n",
    "        clear_memory()\n",
    "        \n",
    "        # Quick validation\n",
    "        print(\"\\nüîç Running validation...\")\n",
    "        metrics = model.val()\n",
    "        \n",
    "        print(\"üìä Validation Results:\")\n",
    "        if hasattr(metrics, 'box'):\n",
    "            print(f\"   mAP50: {metrics.box.map50:.4f}\")\n",
    "            print(f\"   mAP50-95: {metrics.box.map:.4f}\")\n",
    "            print(f\"   Precision: {metrics.box.mp:.4f}\")\n",
    "            print(f\"   Recall: {metrics.box.mr:.4f}\")\n",
    "        else:\n",
    "            print(\"   Validation metrics computed successfully\")\n",
    "        \n",
    "        return save_dir\n",
    "        \n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        print(\"‚ùå Still out of memory! Trying CPU training...\")\n",
    "        clear_memory()\n",
    "        return train_on_cpu()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def train_on_cpu():\n",
    "    \"\"\"Fallback to CPU training\"\"\"\n",
    "    print(\"üñ•Ô∏è  Fallback: Training on CPU...\")\n",
    "    \n",
    "    dataset_path = \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\"\n",
    "    \n",
    "    # Create models directory in dataset path\n",
    "    models_dir = os.path.join(dataset_path, \"models\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    model = YOLO('yolov8n.pt')\n",
    "    \n",
    "    # CPU-optimized configuration\n",
    "    cpu_config = {\n",
    "        'data': f'{dataset_path}/data.yaml',\n",
    "        'epochs': 50,\n",
    "        'imgsz': 320,\n",
    "        'batch': 4,\n",
    "        'name': 'red_plate_cpu',\n",
    "        'patience': 20,\n",
    "        'save': True,\n",
    "        'plots': True,\n",
    "        'device': 'cpu',\n",
    "        'workers': 2,\n",
    "        'project': models_dir,  # Changed to save in dataset/models\n",
    "        'exist_ok': True,\n",
    "        \n",
    "        # Minimal augmentation\n",
    "        'hsv_h': 0.01,\n",
    "        'hsv_s': 0.3,\n",
    "        'hsv_v': 0.2,\n",
    "        'degrees': 0.0,\n",
    "        'translate': 0.02,\n",
    "        'scale': 0.2,\n",
    "        'fliplr': 0.5,\n",
    "        'mosaic': 0.3,\n",
    "        'mixup': 0.0,\n",
    "        'copy_paste': 0.0\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        results = model.train(**cpu_config)\n",
    "        print(\"üéâ CPU training completed!\")\n",
    "        \n",
    "        # Get save directory\n",
    "        save_dir = os.path.join(models_dir, 'red_plate_cpu')\n",
    "        return save_dir\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå CPU training also failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def ultra_minimal_training():\n",
    "    \"\"\"Ultra minimal config for very limited resources\"\"\"\n",
    "    print(\"üî¨ Ultra Minimal Training for Limited Resources\")\n",
    "    \n",
    "    dataset_path = \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\"\n",
    "    \n",
    "    # Create models directory in dataset path\n",
    "    models_dir = os.path.join(dataset_path, \"models\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    # Clear all memory\n",
    "    clear_memory()\n",
    "    \n",
    "    model = YOLO('yolov8n.pt')\n",
    "    \n",
    "    minimal_config = {\n",
    "        'data': f'{dataset_path}/data.yaml',\n",
    "        'epochs': 30,\n",
    "        'imgsz': 256,\n",
    "        'batch': 1,\n",
    "        'name': 'red_plate_minimal',\n",
    "        'patience': 15,\n",
    "        'save': True,\n",
    "        'plots': False,\n",
    "        'device': 0 if torch.cuda.is_available() else 'cpu',\n",
    "        'workers': 0,\n",
    "        'project': models_dir,  # Changed to save in dataset/models\n",
    "        'exist_ok': True,\n",
    "        'cache': False,\n",
    "        'amp': True,\n",
    "        'fraction': 0.8,\n",
    "        \n",
    "        # No augmentation\n",
    "        'hsv_h': 0.0,\n",
    "        'hsv_s': 0.0,\n",
    "        'hsv_v': 0.0,\n",
    "        'degrees': 0.0,\n",
    "        'translate': 0.0,\n",
    "        'scale': 0.0,\n",
    "        'fliplr': 0.0,\n",
    "        'mosaic': 0.0,\n",
    "        'mixup': 0.0,\n",
    "        'copy_paste': 0.0\n",
    "    }\n",
    "    \n",
    "    print(\"‚ö° Ultra minimal configuration:\")\n",
    "    print(f\"   Image size: {minimal_config['imgsz']}\")\n",
    "    print(f\"   Batch size: {minimal_config['batch']}\")\n",
    "    print(f\"   Epochs: {minimal_config['epochs']}\")\n",
    "    print(f\"   Models will be saved to: {models_dir}\")\n",
    "    \n",
    "    try:\n",
    "        results = model.train(**minimal_config)\n",
    "        print(\"üéâ Ultra minimal training completed!\")\n",
    "        \n",
    "        # Get save directory\n",
    "        save_dir = os.path.join(models_dir, 'red_plate_minimal')\n",
    "        return save_dir\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Even minimal training failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def download_pretrained_models(dataset_path):\n",
    "    \"\"\"Download and save YOLO pretrained models to dataset directory\"\"\"\n",
    "    models_dir = os.path.join(dataset_path, \"pretrained_models\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"üì• Downloading pretrained models...\")\n",
    "    \n",
    "    # List of YOLO models to download\n",
    "    models = ['yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt']\n",
    "    \n",
    "    for model_name in models:\n",
    "        try:\n",
    "            print(f\"   Downloading {model_name}...\")\n",
    "            model = YOLO(model_name)\n",
    "            \n",
    "            # Save model to our directory\n",
    "            model_path = os.path.join(models_dir, model_name)\n",
    "            torch.save(model.model.state_dict(), model_path.replace('.pt', '_weights.pt'))\n",
    "            print(f\"   ‚úÖ {model_name} saved to {models_dir}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Failed to download {model_name}: {str(e)}\")\n",
    "    \n",
    "    return models_dir\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set environment variable for memory optimization\n",
    "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "    \n",
    "    # Dataset path\n",
    "    dataset_path = \"C:/Users/minhk/Downloads/code thu√™/AI/NguyenLam/dataset\"\n",
    "    \n",
    "    print(\"Choose training mode:\")\n",
    "    print(\"1. Memory Optimized (Recommended)\")\n",
    "    print(\"2. CPU Training\")\n",
    "    print(\"3. Ultra Minimal\")\n",
    "    print(\"4. Download Pretrained Models Only\")\n",
    "    \n",
    "    choice = input(\"Enter choice (1/2/3/4) [default: 1]: \").strip()\n",
    "    \n",
    "    if choice == \"4\":\n",
    "        models_dir = download_pretrained_models(dataset_path)\n",
    "        print(f\"\\n‚úÖ Pretrained models downloaded to: {models_dir}\")\n",
    "    elif choice == \"2\":\n",
    "        save_dir = train_on_cpu()\n",
    "    elif choice == \"3\":\n",
    "        save_dir = ultra_minimal_training()\n",
    "    else:\n",
    "        save_dir = train_memory_optimized()\n",
    "    \n",
    "    if choice != \"4\":\n",
    "        if save_dir:\n",
    "            print(f\"\\n‚úÖ Training successful! Model saved at: {save_dir}\")\n",
    "            print(f\"üìÅ Best weights: {save_dir}/weights/best.pt\")\n",
    "            print(f\"üìÅ Last weights: {save_dir}/weights/last.pt\")\n",
    "            print(f\"üìÅ Training results: {save_dir}\")\n",
    "            \n",
    "            # Show directory structure\n",
    "            print(f\"\\nüìÇ Directory structure:\")\n",
    "            print(f\"   {dataset_path}/\")\n",
    "            print(f\"   ‚îú‚îÄ‚îÄ models/\")\n",
    "            print(f\"   ‚îÇ   ‚îî‚îÄ‚îÄ {os.path.basename(save_dir)}/\")\n",
    "            print(f\"   ‚îÇ       ‚îú‚îÄ‚îÄ weights/\")\n",
    "            print(f\"   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ best.pt\")\n",
    "            print(f\"   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ last.pt\")\n",
    "            print(f\"   ‚îÇ       ‚îú‚îÄ‚îÄ results.png\")\n",
    "            print(f\"   ‚îÇ       ‚îî‚îÄ‚îÄ confusion_matrix.png\")\n",
    "            print(f\"   ‚îî‚îÄ‚îÄ data.yaml\")\n",
    "            \n",
    "        else:\n",
    "            print(\"\\n‚ùå All training attempts failed. Consider:\")\n",
    "            print(\"   - Using a machine with more GPU memory\")\n",
    "            print(\"   - Training on Google Colab with GPU\")\n",
    "            print(\"   - Using cloud training services\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b73cf80-708d-41fd-a5b1-3e44d5599211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting License Plate Detection & OCR GUI...\n",
      "üì¶ Required packages: easyocr, ultralytics, opencv-python, pillow\n",
      "‚úÖ EasyOCR is available\n",
      "‚úÖ Loading model from: runs/detect/red_plate_memory_opt/weights/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Model classes: {0: 'License_Plate'}\n",
      "üî§ Loading OCR reader...\n",
      "Progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% Complete‚úÖ OCR reader loaded successfully\n",
      "üîÑ Trying camera index 0...\n",
      "‚úÖ Camera 0 initialized: 640x480\n",
      "üî§ Detected plate: 381 (Det: 0.34, OCR: 0.44)\n",
      "üî§ Detected plate: 5347 (Det: 0.44, OCR: 0.57)\n",
      "üî§ Detected plate: 53 (Det: 0.37, OCR: 1.00)\n",
      "üî§ Detected plate: 53070 (Det: 0.32, OCR: 0.42)\n",
      "üî§ Detected plate: 53274 (Det: 0.32, OCR: 0.53)\n",
      "üî§ Detected plate: JBHT (Det: 0.30, OCR: 0.53)\n",
      "üóëÔ∏è Detection history cleared\n",
      "üóëÔ∏è Detection history cleared\n",
      "üî§ Detected plate: BH (Det: 0.12, OCR: 0.99)\n",
      "üî§ Detected plate: 5324 (Det: 0.34, OCR: 0.60)\n",
      "üî§ Detected plate: BH (Det: 0.37, OCR: 0.99)\n",
      "üî§ Detected plate: 5324 (Det: 0.38, OCR: 0.87)\n",
      "üî§ Detected plate: BH (Det: 0.48, OCR: 0.99)\n",
      "üî§ Detected plate: 5324 (Det: 0.67, OCR: 0.56)\n",
      "üóëÔ∏è Detection history cleared\n",
      "üî§ Detected plate: BH5324 (Det: 0.70, OCR: 0.78)\n",
      "üî§ Detected plate: B4P53224 (Det: 0.65, OCR: 0.43)\n",
      "üî§ Detected plate: BH (Det: 0.10, OCR: 0.99)\n",
      "üî§ Detected plate: I537 (Det: 0.10, OCR: 0.77)\n",
      "üî§ Detected plate: 15374 (Det: 0.27, OCR: 0.61)\n",
      "üî§ Detected plate: BHF (Det: 0.32, OCR: 0.66)\n",
      "üî§ Detected plate: B4 (Det: 0.22, OCR: 0.72)\n",
      "üî§ Detected plate: 5374 (Det: 0.60, OCR: 1.00)\n",
      "üî§ Detected plate: BH (Det: 0.50, OCR: 0.85)\n",
      "üî§ Detected plate: 5374 (Det: 0.66, OCR: 1.00)\n",
      "üî§ Detected plate: BH (Det: 0.54, OCR: 0.95)\n",
      "üî§ Detected plate: 5374 (Det: 0.63, OCR: 0.99)\n",
      "üî§ Detected plate: BH (Det: 0.49, OCR: 0.70)\n",
      "üî§ Detected plate: BH] (Det: 0.35, OCR: 0.85)\n",
      "üî§ Detected plate: 5320 (Det: 0.30, OCR: 0.87)\n",
      "üî§ Detected plate: 15324 (Det: 0.50, OCR: 0.53)\n",
      "üî§ Detected plate: BH (Det: 0.17, OCR: 0.99)\n",
      "üî§ Detected plate: B] (Det: 0.40, OCR: 1.00)\n",
      "üî§ Detected plate: 5324 (Det: 0.55, OCR: 0.49)\n",
      "üî§ Detected plate: BH (Det: 0.58, OCR: 0.87)\n",
      "üî§ Detected plate: 15324 (Det: 0.72, OCR: 0.41)\n",
      "üî§ Detected plate: 2 BH (Det: 0.65, OCR: 0.41)\n",
      "üî§ Detected plate: 5320 (Det: 0.68, OCR: 0.46)\n",
      "üî§ Detected plate: BH (Det: 0.71, OCR: 0.73)\n",
      "üî§ Detected plate: 15324 (Det: 0.57, OCR: 0.49)\n",
      "üî§ Detected plate: BH] (Det: 0.44, OCR: 0.56)\n",
      "üî§ Detected plate: 5324 (Det: 0.37, OCR: 0.97)\n",
      "üî§ Detected plate: BH] (Det: 0.58, OCR: 0.88)\n",
      "üî§ Detected plate: 15324 (Det: 0.63, OCR: 0.40)\n",
      "üî§ Detected plate: E5324 (Det: 0.66, OCR: 0.34)\n",
      "üî§ Detected plate: BIF (Det: 0.43, OCR: 0.62)\n",
      "üî§ Detected plate: BH (Det: 0.61, OCR: 0.78)\n",
      "üî§ Detected plate: 15324 (Det: 0.65, OCR: 0.46)\n",
      "üî§ Detected plate: BH] (Det: 0.66, OCR: 0.87)\n",
      "üî§ Detected plate: BH (Det: 0.58, OCR: 0.73)\n",
      "üî§ Detected plate: BH (Det: 0.45, OCR: 0.44)\n",
      "üî§ Detected plate: BI (Det: 0.70, OCR: 0.63)\n",
      "üî§ Detected plate: BH (Det: 0.71, OCR: 0.98)\n",
      "üî§ Detected plate: BH] (Det: 0.71, OCR: 0.85)\n",
      "üî§ Detected plate: BH (Det: 0.74, OCR: 0.76)\n",
      "üî§ Detected plate: 15324 (Det: 0.73, OCR: 0.43)\n",
      "üî§ Detected plate: BH (Det: 0.70, OCR: 0.98)\n",
      "üî§ Detected plate: 5324 (Det: 0.71, OCR: 0.55)\n",
      "üî§ Detected plate: BH (Det: 0.70, OCR: 1.00)\n",
      "üî§ Detected plate: 5324 (Det: 0.70, OCR: 0.99)\n",
      "üóëÔ∏è Detection history cleared\n",
      "üî§ Detected plate: BI1537 (Det: 0.33, OCR: 0.34)\n",
      "üî§ Detected plate: BW5374 (Det: 0.38, OCR: 0.39)\n",
      "üî§ Detected plate: BI1537 (Det: 0.14, OCR: 0.51)\n",
      "üî§ Detected plate: BI1537 (Det: 0.28, OCR: 0.31)\n",
      "üî§ Detected plate: BI15372 (Det: 0.37, OCR: 0.32)\n",
      "üî§ Detected plate: 815372 (Det: 0.21, OCR: 0.36)\n",
      "üî§ Detected plate: B115372 (Det: 0.29, OCR: 0.65)\n",
      "üëã Application closed\n",
      "üîö Application terminated\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox, scrolledtext\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import os\n",
    "import easyocr\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "class LicensePlateOCRApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"üî¥ Red License Plate Detection & OCR\")\n",
    "        self.root.geometry(\"1400x900\")\n",
    "        self.root.configure(bg='#f0f0f0')\n",
    "        \n",
    "        # Initialize variables\n",
    "        self.cap = None\n",
    "        self.is_running = False\n",
    "        self.frame_queue = queue.Queue(maxsize=2)\n",
    "        self.confidence_threshold = 0.3\n",
    "        self.current_frame = None\n",
    "        self.detection_count = 0\n",
    "        self.fps = 0\n",
    "        self.detected_plates = []\n",
    "        \n",
    "        # OCR settings\n",
    "        self.ocr_enabled = True\n",
    "        self.ocr_reader = None\n",
    "        \n",
    "        # Load model and OCR\n",
    "        self.load_model()\n",
    "        self.load_ocr()\n",
    "        \n",
    "        # Setup GUI\n",
    "        self.setup_gui()\n",
    "        \n",
    "        # Initialize webcam\n",
    "        self.initialize_webcam()\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load the trained YOLO model\"\"\"\n",
    "        try:\n",
    "            model_paths = [\n",
    "                \"runs/detect/red_plate_memory_opt/weights/best.pt\",\n",
    "                \"runs/detect/red_plate_memory_opt/weights/last.pt\",\n",
    "                \"runs/detect/red_plate_cpu/weights/best.pt\",\n",
    "                \"runs/detect/red_plate_minimal/weights/best.pt\"\n",
    "            ]\n",
    "            \n",
    "            model_loaded = False\n",
    "            for path in model_paths:\n",
    "                if os.path.exists(path):\n",
    "                    print(f\"‚úÖ Loading model from: {path}\")\n",
    "                    self.model = YOLO(path)\n",
    "                    model_loaded = True\n",
    "                    break\n",
    "            \n",
    "            if not model_loaded:\n",
    "                print(\"‚ö†Ô∏è  Using default YOLOv8n model\")\n",
    "                self.model = YOLO('yolov8n.pt')\n",
    "            \n",
    "            print(f\"üìä Model classes: {self.model.names}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading model: {e}\")\n",
    "            messagebox.showerror(\"Model Error\", f\"Cannot load model: {e}\")\n",
    "            self.model = None\n",
    "    \n",
    "    def load_ocr(self):\n",
    "        \"\"\"Load EasyOCR reader\"\"\"\n",
    "        try:\n",
    "            print(\"üî§ Loading OCR reader...\")\n",
    "            # Initialize EasyOCR with Vietnamese and English\n",
    "            self.ocr_reader = easyocr.Reader(['vi', 'en'], gpu=True if cv2.cuda.getCudaEnabledDeviceCount() > 0 else False)\n",
    "            print(\"‚úÖ OCR reader loaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading OCR: {e}\")\n",
    "            try:\n",
    "                # Fallback without GPU\n",
    "                self.ocr_reader = easyocr.Reader(['vi', 'en'], gpu=False)\n",
    "                print(\"‚úÖ OCR reader loaded (CPU mode)\")\n",
    "            except Exception as e2:\n",
    "                print(f\"‚ùå Cannot load OCR: {e2}\")\n",
    "                self.ocr_reader = None\n",
    "                messagebox.showwarning(\"OCR Warning\", \"Cannot load OCR. Text recognition will be disabled.\")\n",
    "    \n",
    "    def setup_gui(self):\n",
    "        \"\"\"Setup the enhanced GUI with OCR features\"\"\"\n",
    "        # Main container\n",
    "        main_frame = ttk.Frame(self.root, padding=\"10\")\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Title\n",
    "        title_frame = ttk.Frame(main_frame)\n",
    "        title_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        title_label = ttk.Label(title_frame, text=\"üî¥ Red License Plate Detection & OCR System\", \n",
    "                               font=('Arial', 18, 'bold'))\n",
    "        title_label.pack()\n",
    "        \n",
    "        # Content frame\n",
    "        content_frame = ttk.Frame(main_frame)\n",
    "        content_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Left panel - Video display\n",
    "        video_frame = ttk.LabelFrame(content_frame, text=\"üì∑ Live Camera Feed\", padding=\"10\")\n",
    "        video_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(0, 10))\n",
    "        \n",
    "        # Video display label\n",
    "        self.video_label = ttk.Label(video_frame, text=\"üì∑ Initializing camera...\", \n",
    "                                    background='black', foreground='white',\n",
    "                                    font=('Arial', 12))\n",
    "        self.video_label.pack(expand=True)\n",
    "        \n",
    "        # Right panel - Split into top and bottom\n",
    "        right_panel = ttk.Frame(content_frame)\n",
    "        right_panel.pack(side=tk.RIGHT, fill=tk.BOTH, padx=(10, 0))\n",
    "        \n",
    "        # Controls panel (top right)\n",
    "        control_frame = ttk.LabelFrame(right_panel, text=\"üéõÔ∏è Controls\", padding=\"10\")\n",
    "        control_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        # Confidence control\n",
    "        conf_frame = ttk.Frame(control_frame)\n",
    "        conf_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        ttk.Label(conf_frame, text=\"üéØ Detection Confidence:\", font=('Arial', 10, 'bold')).pack(anchor=tk.W)\n",
    "        \n",
    "        self.confidence_var = tk.DoubleVar(value=self.confidence_threshold)\n",
    "        self.confidence_scale = ttk.Scale(conf_frame, from_=0.05, to=0.95, \n",
    "                                         variable=self.confidence_var, orient='horizontal', \n",
    "                                         length=200, command=self.update_confidence)\n",
    "        self.confidence_scale.pack(fill=tk.X, pady=2)\n",
    "        \n",
    "        self.confidence_label = ttk.Label(conf_frame, text=f\"Value: {self.confidence_threshold:.2f}\")\n",
    "        self.confidence_label.pack(anchor=tk.W)\n",
    "        \n",
    "        # OCR settings\n",
    "        ocr_frame = ttk.Frame(control_frame)\n",
    "        ocr_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        self.ocr_var = tk.BooleanVar(value=self.ocr_enabled)\n",
    "        ocr_check = ttk.Checkbutton(ocr_frame, text=\"üî§ Enable OCR Text Recognition\", \n",
    "                                   variable=self.ocr_var, command=self.toggle_ocr)\n",
    "        ocr_check.pack(anchor=tk.W)\n",
    "        \n",
    "        # Control buttons\n",
    "        button_frame = ttk.Frame(control_frame)\n",
    "        button_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        self.start_button = ttk.Button(button_frame, text=\"‚ñ∂Ô∏è Start Detection\", \n",
    "                                      command=self.toggle_detection, width=20)\n",
    "        self.start_button.pack(fill=tk.X, pady=1)\n",
    "        \n",
    "        self.screenshot_button = ttk.Button(button_frame, text=\"üì∏ Take Screenshot\", \n",
    "                                           command=self.take_screenshot, width=20)\n",
    "        self.screenshot_button.pack(fill=tk.X, pady=1)\n",
    "        \n",
    "        self.save_plates_button = ttk.Button(button_frame, text=\"üíæ Save Detected Plates\", \n",
    "                                            command=self.save_detected_plates, width=20)\n",
    "        self.save_plates_button.pack(fill=tk.X, pady=1)\n",
    "        \n",
    "        self.clear_button = ttk.Button(button_frame, text=\"üóëÔ∏è Clear History\", \n",
    "                                      command=self.clear_history, width=20)\n",
    "        self.clear_button.pack(fill=tk.X, pady=1)\n",
    "        \n",
    "        self.reset_button = ttk.Button(button_frame, text=\"üîÑ Reset Camera\", \n",
    "                                      command=self.reset_camera, width=20)\n",
    "        self.reset_button.pack(fill=tk.X, pady=1)\n",
    "        \n",
    "        self.quit_button = ttk.Button(button_frame, text=\"üö™ Quit\", \n",
    "                                     command=self.quit_app, width=20)\n",
    "        self.quit_button.pack(fill=tk.X, pady=1)\n",
    "        \n",
    "        # Information display\n",
    "        info_frame = ttk.LabelFrame(right_panel, text=\"üìä Real-time Info\", padding=\"10\")\n",
    "        info_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        self.detection_var = tk.StringVar(value=\"Detections: 0\")\n",
    "        ttk.Label(info_frame, textvariable=self.detection_var, font=('Arial', 10)).pack(anchor=tk.W)\n",
    "        \n",
    "        self.fps_var = tk.StringVar(value=\"FPS: 0.0\")\n",
    "        ttk.Label(info_frame, textvariable=self.fps_var, font=('Arial', 10)).pack(anchor=tk.W)\n",
    "        \n",
    "        self.camera_var = tk.StringVar(value=\"Camera: Not connected\")\n",
    "        ttk.Label(info_frame, textvariable=self.camera_var, font=('Arial', 10)).pack(anchor=tk.W)\n",
    "        \n",
    "        self.model_var = tk.StringVar(value=\"Model: Loading...\")\n",
    "        ttk.Label(info_frame, textvariable=self.model_var, font=('Arial', 10)).pack(anchor=tk.W)\n",
    "        \n",
    "        self.ocr_status_var = tk.StringVar(value=\"OCR: Ready\" if self.ocr_reader else \"OCR: Not available\")\n",
    "        ttk.Label(info_frame, textvariable=self.ocr_status_var, font=('Arial', 10)).pack(anchor=tk.W)\n",
    "        \n",
    "        # Detected plates display\n",
    "        plates_frame = ttk.LabelFrame(right_panel, text=\"üî§ Detected License Plates\", padding=\"10\")\n",
    "        plates_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Create treeview for detected plates\n",
    "        columns = ('Time', 'Plate Text', 'Confidence', 'OCR Confidence')\n",
    "        self.plates_tree = ttk.Treeview(plates_frame, columns=columns, show='headings', height=8)\n",
    "        \n",
    "        # Define column headings and widths\n",
    "        self.plates_tree.heading('Time', text='üïê Time')\n",
    "        self.plates_tree.heading('Plate Text', text='üî§ Plate Text')\n",
    "        self.plates_tree.heading('Confidence', text='üéØ Det. Conf.')\n",
    "        self.plates_tree.heading('OCR Confidence', text='üìñ OCR Conf.')\n",
    "        \n",
    "        self.plates_tree.column('Time', width=80)\n",
    "        self.plates_tree.column('Plate Text', width=120)\n",
    "        self.plates_tree.column('Confidence', width=80)\n",
    "        self.plates_tree.column('OCR Confidence', width=80)\n",
    "        \n",
    "        # Add scrollbar\n",
    "        scrollbar = ttk.Scrollbar(plates_frame, orient=tk.VERTICAL, command=self.plates_tree.yview)\n",
    "        self.plates_tree.configure(yscrollcommand=scrollbar.set)\n",
    "        \n",
    "        self.plates_tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        \n",
    "        # Status bar\n",
    "        self.status_var = tk.StringVar(value=\"üì± Ready - Click 'Start Detection' to begin\")\n",
    "        status_bar = ttk.Label(main_frame, textvariable=self.status_var, \n",
    "                              relief=tk.SUNKEN, anchor=tk.W, font=('Arial', 9))\n",
    "        status_bar.pack(fill=tk.X, pady=(10, 0))\n",
    "        \n",
    "        # Update model info\n",
    "        if self.model:\n",
    "            model_info = f\"Model: Custom ({len(self.model.names)} classes)\"\n",
    "        else:\n",
    "            model_info = \"Model: Not loaded\"\n",
    "        self.model_var.set(model_info)\n",
    "    \n",
    "    def update_confidence(self, value):\n",
    "        \"\"\"Update confidence threshold\"\"\"\n",
    "        self.confidence_threshold = float(value)\n",
    "        self.confidence_label.config(text=f\"Value: {self.confidence_threshold:.2f}\")\n",
    "    \n",
    "    def toggle_ocr(self):\n",
    "        \"\"\"Toggle OCR functionality\"\"\"\n",
    "        self.ocr_enabled = self.ocr_var.get()\n",
    "        status = \"Enabled\" if self.ocr_enabled else \"Disabled\"\n",
    "        self.ocr_status_var.set(f\"OCR: {status}\")\n",
    "        print(f\"üî§ OCR {status}\")\n",
    "    \n",
    "    def preprocess_for_ocr(self, image):\n",
    "        \"\"\"Preprocess license plate image for better OCR\"\"\"\n",
    "        try:\n",
    "            # Convert to grayscale\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Apply Gaussian blur to reduce noise\n",
    "            blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "            \n",
    "            # Apply adaptive thresholding\n",
    "            thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                         cv2.THRESH_BINARY, 11, 2)\n",
    "            \n",
    "            # Morphological operations to clean up\n",
    "            kernel = np.ones((2, 2), np.uint8)\n",
    "            cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "            \n",
    "            # Resize for better OCR (make it larger)\n",
    "            height, width = cleaned.shape\n",
    "            if height < 50:\n",
    "                scale_factor = 50 / height\n",
    "                new_width = int(width * scale_factor)\n",
    "                cleaned = cv2.resize(cleaned, (new_width, 50), interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "            return cleaned\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå OCR preprocessing error: {e}\")\n",
    "            return image\n",
    "    \n",
    "    def clean_plate_text(self, text):\n",
    "        \"\"\"Clean and format detected plate text\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        \n",
    "        # Remove special characters and keep only alphanumeric\n",
    "        cleaned = re.sub(r'[^A-Za-z0-9]', '', text.upper())\n",
    "        \n",
    "        # Vietnamese license plate patterns\n",
    "        patterns = [\n",
    "            r'^(\\d{2}[A-Z]\\d{4,5})$',  # 12A1234 or 12A12345\n",
    "            r'^(\\d{2}[A-Z]{2}\\d{3,4})$',  # 12AB123 or 12AB1234\n",
    "            r'^(\\d{2}[A-Z]\\d{3}\\.\\d{2})$',  # 12A123.45\n",
    "            r'^([A-Z]{2}\\d{4,5})$',  # AB1234 or AB12345\n",
    "        ]\n",
    "        \n",
    "        # Try to match Vietnamese patterns\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, cleaned)\n",
    "            if match:\n",
    "                return match.group(1)\n",
    "        \n",
    "        # If no pattern matches, return cleaned text if it's reasonable length\n",
    "        if 4 <= len(cleaned) <= 10:\n",
    "            return cleaned\n",
    "        \n",
    "        return text.strip() if text.strip() else \"UNKNOWN\"\n",
    "    \n",
    "    def perform_ocr(self, plate_image):\n",
    "        \"\"\"Perform OCR on license plate image\"\"\"\n",
    "        if not self.ocr_reader or not self.ocr_enabled:\n",
    "            return \"OCR Disabled\", 0.0\n",
    "        \n",
    "        try:\n",
    "            # Preprocess image for better OCR\n",
    "            processed_image = self.preprocess_for_ocr(plate_image)\n",
    "            \n",
    "            # Perform OCR\n",
    "            results = self.ocr_reader.readtext(processed_image, detail=1, paragraph=False)\n",
    "            \n",
    "            if not results:\n",
    "                return \"NO TEXT\", 0.0\n",
    "            \n",
    "            # Find the best result (highest confidence)\n",
    "            best_text = \"\"\n",
    "            best_confidence = 0.0\n",
    "            \n",
    "            for (bbox, text, confidence) in results:\n",
    "                if confidence > best_confidence and len(text.strip()) > 0:\n",
    "                    best_text = text\n",
    "                    best_confidence = confidence\n",
    "            \n",
    "            if best_text:\n",
    "                cleaned_text = self.clean_plate_text(best_text)\n",
    "                return cleaned_text, best_confidence\n",
    "            else:\n",
    "                return \"NO TEXT\", 0.0\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå OCR error: {e}\")\n",
    "            return \"OCR ERROR\", 0.0\n",
    "    \n",
    "    def add_detected_plate(self, plate_text, det_confidence, ocr_confidence):\n",
    "        \"\"\"Add detected plate to the history\"\"\"\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        # Check if this plate was recently detected (avoid duplicates)\n",
    "        recent_plates = [item for item in self.detected_plates if item['time'] > time.time() - 2]\n",
    "        for plate in recent_plates:\n",
    "            if plate['text'] == plate_text:\n",
    "                return  # Skip duplicate\n",
    "        \n",
    "        # Add to internal list\n",
    "        plate_data = {\n",
    "            'time': time.time(),\n",
    "            'timestamp': current_time,\n",
    "            'text': plate_text,\n",
    "            'det_confidence': det_confidence,\n",
    "            'ocr_confidence': ocr_confidence\n",
    "        }\n",
    "        self.detected_plates.append(plate_data)\n",
    "        \n",
    "        # Add to treeview\n",
    "        self.plates_tree.insert('', 0, values=(\n",
    "            current_time,\n",
    "            plate_text,\n",
    "            f\"{det_confidence:.2f}\",\n",
    "            f\"{ocr_confidence:.2f}\" if ocr_confidence > 0 else \"N/A\"\n",
    "        ))\n",
    "        \n",
    "        # Keep only last 50 entries\n",
    "        if len(self.detected_plates) > 50:\n",
    "            self.detected_plates = self.detected_plates[-50:]\n",
    "            \n",
    "        # Remove old entries from treeview\n",
    "        children = self.plates_tree.get_children()\n",
    "        if len(children) > 50:\n",
    "            for item in children[50:]:\n",
    "                self.plates_tree.delete(item)\n",
    "        \n",
    "        print(f\"üî§ Detected plate: {plate_text} (Det: {det_confidence:.2f}, OCR: {ocr_confidence:.2f})\")\n",
    "    \n",
    "    def save_detected_plates(self):\n",
    "        \"\"\"Save detected plates to file\"\"\"\n",
    "        if not self.detected_plates:\n",
    "            messagebox.showwarning(\"No Data\", \"No license plates detected yet.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"detected_plates_{timestamp}.txt\"\n",
    "            \n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"Red License Plate Detection Results\\n\")\n",
    "                f.write(\"=\"*50 + \"\\n\")\n",
    "                f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                f.write(f\"Total detections: {len(self.detected_plates)}\\n\\n\")\n",
    "                \n",
    "                for i, plate in enumerate(self.detected_plates, 1):\n",
    "                    f.write(f\"{i:3d}. Time: {plate['timestamp']} | \")\n",
    "                    f.write(f\"Plate: {plate['text']:12s} | \")\n",
    "                    f.write(f\"Det.Conf: {plate['det_confidence']:.3f} | \")\n",
    "                    f.write(f\"OCR.Conf: {plate['ocr_confidence']:.3f}\\n\")\n",
    "            \n",
    "            messagebox.showinfo(\"Saved\", f\"Detected plates saved to:\\n{filename}\")\n",
    "            self.status_var.set(f\"üíæ Plates saved to {filename}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Save Error\", f\"Cannot save file: {e}\")\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear detection history\"\"\"\n",
    "        self.detected_plates.clear()\n",
    "        for item in self.plates_tree.get_children():\n",
    "            self.plates_tree.delete(item)\n",
    "        self.status_var.set(\"üóëÔ∏è Detection history cleared\")\n",
    "        print(\"üóëÔ∏è Detection history cleared\")\n",
    "    \n",
    "    def initialize_webcam(self):\n",
    "        \"\"\"Initialize webcam connection\"\"\"\n",
    "        try:\n",
    "            # Try different camera indices\n",
    "            for camera_idx in [0, 1, 2]:\n",
    "                print(f\"üîÑ Trying camera index {camera_idx}...\")\n",
    "                test_cap = cv2.VideoCapture(camera_idx)\n",
    "                \n",
    "                if test_cap.isOpened():\n",
    "                    # Test if we can read a frame\n",
    "                    ret, frame = test_cap.read()\n",
    "                    if ret:\n",
    "                        self.cap = test_cap\n",
    "                        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "                        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "                        self.cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "                        \n",
    "                        width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                        height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                        \n",
    "                        print(f\"‚úÖ Camera {camera_idx} initialized: {width}x{height}\")\n",
    "                        self.camera_var.set(f\"Camera: {camera_idx} ({width}x{height})\")\n",
    "                        self.status_var.set(f\"üìπ Camera {camera_idx} ready - Click 'Start Detection'\")\n",
    "                        return\n",
    "                    else:\n",
    "                        test_cap.release()\n",
    "                else:\n",
    "                    test_cap.release()\n",
    "            \n",
    "            # No camera found\n",
    "            self.cap = None\n",
    "            self.camera_var.set(\"Camera: Not found\")\n",
    "            self.status_var.set(\"‚ùå No camera detected\")\n",
    "            messagebox.showwarning(\"Camera Warning\", \n",
    "                                 \"No camera detected. Please connect a camera and click 'Reset Camera'\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Camera initialization error: {e}\")\n",
    "            self.cap = None\n",
    "            self.camera_var.set(\"Camera: Error\")\n",
    "            self.status_var.set(\"‚ùå Camera initialization failed\")\n",
    "    \n",
    "    def toggle_detection(self):\n",
    "        \"\"\"Start or stop detection\"\"\"\n",
    "        if not self.is_running:\n",
    "            if self.cap is None:\n",
    "                self.reset_camera()\n",
    "                if self.cap is None:\n",
    "                    messagebox.showerror(\"Error\", \"Cannot start detection: No camera available\")\n",
    "                    return\n",
    "            \n",
    "            if self.model is None:\n",
    "                messagebox.showerror(\"Error\", \"Cannot start detection: No model loaded\")\n",
    "                return\n",
    "            \n",
    "            self.is_running = True\n",
    "            self.start_button.config(text=\"‚èπÔ∏è Stop Detection\")\n",
    "            self.status_var.set(\"üîÑ Detection running...\")\n",
    "            \n",
    "            # Start detection thread\n",
    "            self.detection_thread = threading.Thread(target=self.detection_loop, daemon=True)\n",
    "            self.detection_thread.start()\n",
    "            \n",
    "            # Start display update\n",
    "            self.update_display()\n",
    "        else:\n",
    "            self.stop_detection()\n",
    "    \n",
    "    def stop_detection(self):\n",
    "        \"\"\"Stop detection\"\"\"\n",
    "        self.is_running = False\n",
    "        self.start_button.config(text=\"‚ñ∂Ô∏è Start Detection\")\n",
    "        self.status_var.set(\"‚èπÔ∏è Detection stopped\")\n",
    "        self.detection_var.set(\"Detections: 0\")\n",
    "        self.fps_var.set(\"FPS: 0.0\")\n",
    "    \n",
    "    def detection_loop(self):\n",
    "        \"\"\"Main detection loop with OCR\"\"\"\n",
    "        fps_counter = 0\n",
    "        fps_start_time = time.time()\n",
    "        last_ocr_time = 0\n",
    "        \n",
    "        while self.is_running and self.cap is not None:\n",
    "            try:\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    print(\"‚ùå Cannot read frame from camera\")\n",
    "                    break\n",
    "                \n",
    "                current_time = time.time()\n",
    "                \n",
    "                # Run detection\n",
    "                if self.model:\n",
    "                    results = self.model(frame, conf=self.confidence_threshold, verbose=False)\n",
    "                    \n",
    "                    detection_count = 0\n",
    "                    for r in results:\n",
    "                        if len(r.boxes) > 0:\n",
    "                            detection_count = len(r.boxes)\n",
    "                            for box in r.boxes:\n",
    "                                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                                conf = box.conf[0].cpu().numpy()\n",
    "                                \n",
    "                                # Draw rectangle\n",
    "                                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 3)\n",
    "                                \n",
    "                                # Extract license plate region for OCR\n",
    "                                plate_region = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "                                \n",
    "                                # Perform OCR (limit frequency to avoid slowdown)\n",
    "                                plate_text = \"DETECTING...\"\n",
    "                                ocr_conf = 0.0\n",
    "                                \n",
    "                                if (self.ocr_enabled and self.ocr_reader and \n",
    "                                    current_time - last_ocr_time > 1.0 and  # OCR every 1 second\n",
    "                                    plate_region.shape[0] > 20 and plate_region.shape[1] > 40):  # Minimum size\n",
    "                                    \n",
    "                                    plate_text, ocr_conf = self.perform_ocr(plate_region)\n",
    "                                    last_ocr_time = current_time\n",
    "                                    \n",
    "                                    # Add to detection history if OCR successful\n",
    "                                    if plate_text != \"DETECTING...\" and plate_text != \"NO TEXT\" and ocr_conf > 0.3:\n",
    "                                        self.add_detected_plate(plate_text, conf, ocr_conf)\n",
    "                                \n",
    "                                # Draw label with OCR result\n",
    "                                label = f\"{plate_text} ({conf:.2f})\"\n",
    "                                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "                                \n",
    "                                # Draw label background\n",
    "                                cv2.rectangle(frame, (int(x1), int(y1-35)), \n",
    "                                            (int(x1) + label_size[0] + 10, int(y1)), (0, 255, 0), -1)\n",
    "                                \n",
    "                                # Draw label text\n",
    "                                cv2.putText(frame, label, (int(x1) + 5, int(y1-10)), \n",
    "                                          cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "                    \n",
    "                    self.detection_count = detection_count\n",
    "                \n",
    "                # Calculate FPS\n",
    "                fps_counter += 1\n",
    "                if fps_counter % 30 == 0:\n",
    "                    current_time = time.time()\n",
    "                    elapsed = current_time - fps_start_time\n",
    "                    if elapsed > 0:\n",
    "                        self.fps = 30 / elapsed\n",
    "                    fps_start_time = current_time\n",
    "                    fps_counter = 0\n",
    "                \n",
    "                # Put frame in queue for display\n",
    "                try:\n",
    "                    self.frame_queue.put_nowait(frame)\n",
    "                except queue.Full:\n",
    "                    try:\n",
    "                        self.frame_queue.get_nowait()  # Remove old frame\n",
    "                        self.frame_queue.put_nowait(frame)\n",
    "                    except queue.Empty:\n",
    "                        pass\n",
    "                \n",
    "                time.sleep(0.03)  # ~30 FPS\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Detection loop error: {e}\")\n",
    "                break\n",
    "        \n",
    "        if self.is_running:\n",
    "            self.root.after(0, self.stop_detection)\n",
    "    \n",
    "    def update_display(self):\n",
    "        \"\"\"Update the video display\"\"\"\n",
    "        if self.is_running:\n",
    "            try:\n",
    "                frame = self.frame_queue.get_nowait()\n",
    "                self.current_frame = frame.copy()\n",
    "                \n",
    "                # Convert frame to display format\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_pil = Image.fromarray(frame_rgb)\n",
    "                \n",
    "                # Resize frame to fit display\n",
    "                display_width = 640\n",
    "                display_height = 480\n",
    "                frame_pil = frame_pil.resize((display_width, display_height), Image.Resampling.LANCZOS)\n",
    "                \n",
    "                # Convert to PhotoImage\n",
    "                frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "                \n",
    "                # Update label\n",
    "                self.video_label.config(image=frame_tk, text=\"\")\n",
    "                self.video_label.image = frame_tk  # Keep a reference\n",
    "                \n",
    "                # Update info displays\n",
    "                self.detection_var.set(f\"Detections: {self.detection_count}\")\n",
    "                self.fps_var.set(f\"FPS: {self.fps:.1f}\")\n",
    "                \n",
    "            except queue.Empty:\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                print(f\"Display update error: {e}\")\n",
    "            \n",
    "            # Schedule next update\n",
    "            self.root.after(30, self.update_display)\n",
    "    \n",
    "    def take_screenshot(self):\n",
    "        \"\"\"Take a screenshot of current frame\"\"\"\n",
    "        if hasattr(self, 'current_frame') and self.current_frame is not None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"license_plate_ocr_screenshot_{timestamp}.jpg\"\n",
    "            \n",
    "            try:\n",
    "                cv2.imwrite(filename, self.current_frame)\n",
    "                messagebox.showinfo(\"Screenshot Saved\", f\"Screenshot saved as:\\n{filename}\")\n",
    "                self.status_var.set(f\"üì∏ Screenshot saved: {filename}\")\n",
    "                print(f\"üì∏ Screenshot saved: {filename}\")\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Screenshot Error\", f\"Failed to save screenshot: {e}\")\n",
    "        else:\n",
    "            messagebox.showwarning(\"No Frame\", \"No frame available for screenshot.\\nStart detection first.\")\n",
    "    \n",
    "    def reset_camera(self):\n",
    "        \"\"\"Reset camera connection\"\"\"\n",
    "        self.stop_detection()\n",
    "        \n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "            self.cap = None\n",
    "        \n",
    "        self.status_var.set(\"üîÑ Resetting camera...\")\n",
    "        self.root.update()\n",
    "        \n",
    "        time.sleep(1)  # Wait a moment\n",
    "        self.initialize_webcam()\n",
    "    \n",
    "    def quit_app(self):\n",
    "        \"\"\"Clean up and quit application\"\"\"\n",
    "        self.stop_detection()\n",
    "        \n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        \n",
    "        self.root.quit()\n",
    "        self.root.destroy()\n",
    "        print(\"üëã Application closed\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the OCR application\"\"\"\n",
    "    print(\"üöÄ Starting License Plate Detection & OCR GUI...\")\n",
    "    print(\"üì¶ Required packages: easyocr, ultralytics, opencv-python, pillow\")\n",
    "    \n",
    "    # Check if EasyOCR is installed\n",
    "    try:\n",
    "        import easyocr\n",
    "        print(\"‚úÖ EasyOCR is available\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå EasyOCR not found. Installing...\")\n",
    "        try:\n",
    "            import subprocess\n",
    "            subprocess.check_call([\"pip\", \"install\", \"easyocr\"])\n",
    "            print(\"‚úÖ EasyOCR installed successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Cannot install EasyOCR: {e}\")\n",
    "            print(\"üí° Please run: pip install easyocr\")\n",
    "    \n",
    "    # Create and configure root window\n",
    "    root = tk.Tk()\n",
    "    \n",
    "    # Set up styles\n",
    "    style = ttk.Style()\n",
    "    style.theme_use('clam')  # Use a modern theme\n",
    "    \n",
    "    # Create and run application\n",
    "    app = LicensePlateOCRApp(root)\n",
    "    \n",
    "    try:\n",
    "        root.mainloop()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚èπÔ∏è Application interrupted by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Application error: {e}\")\n",
    "    finally:\n",
    "        if hasattr(app, 'cap') and app.cap:\n",
    "            app.cap.release()\n",
    "        print(\"üîö Application terminated\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b5c42-ca5c-4d54-bfb9-a6771abf2098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
